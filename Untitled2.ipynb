{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set GPU device to use\n",
    "    torch.cuda.set_device(0)  # Replace '0' with the index of your desired GPU if you have multiple GPUs\n",
    "\n",
    "    # Set GPU power limit to 70%\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_properties = torch.cuda.get_device_properties(gpu_device)\n",
    "    gpu_power_limit = int(0.7 * gpu_properties.total_memory)\n",
    "    torch.cuda.set_limit(gpu_device, gpu_power_limit)\n",
    "else:\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validate the model #\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss = validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "epochs = 3200\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model architecture: \", net)\n",
    "traincsv_file = 'data' + '/' + 'train.csv'\n",
    "validationcsv_file = 'data' + '/' + 'val.csv'\n",
    "train_img_dir = 'data' + '/' + 'train/'\n",
    "validation_img_dir = 'data' + '/' + 'val/'\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = Plain_Dataset(csv_file=traincsv_file, img_dir=train_img_dir, datatype='train', transform=transformation)\n",
    "validation_dataset = Plain_Dataset(csv_file=validationcsv_file, img_dir=validation_img_dir, datatype='val', transform=transformation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01286d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set GPU device to use\n",
    "    torch.cuda.set_device(0)  # Replace '0' with the index of your desired GPU if you have multiple GPUs\n",
    "\n",
    "    # Set GPU power limit to 70% using nvidia-smi command\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_power_limit = int(0.7 * torch.cuda.get_device_properties(gpu_device).total_memory)\n",
    "    subprocess.run(['nvidia-smi', '-i', str(gpu_device), '-pl', str(gpu_power_limit)])\n",
    "else:\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validate the model #\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss = validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "epochs = 3200\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model architecture: \", net)\n",
    "traincsv_file = 'data' + '/' + 'train.csv'\n",
    "validationcsv_file = 'data' + '/' + 'val.csv'\n",
    "train_img_dir = 'data' + '/' + 'train/'\n",
    "validation_img_dir = 'data' + '/' + 'val/'\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = Plain_Dataset(csv_file=traincsv_file, img_dir=train_img_dir, datatype='train', transform=transformation)\n",
    "validation_dataset = Plain_Dataset(csv_file=validationcsv_file, img_dir=validation_img_dir, datatype='val', transform=transformation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Set GPU device to use\n",
    "    torch.cuda.set_device(0)  # Replace '0' with the index of your desired GPU if you have multiple GPUs\n",
    "\n",
    "    # Set GPU power limit to 80% using nvidia-smi command\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_power_limit = int(0.8 * torch.cuda.get_device_properties(gpu_device).total_memory)\n",
    "    subprocess.run(['nvidia-smi', '-i', str(gpu_device), '-pl', str(gpu_power_limit)])\n",
    "else:\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validate the model #\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss = validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "epochs = 3200\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model architecture: \", net)\n",
    "traincsv_file = 'data' + '/' + 'train.csv'\n",
    "validationcsv_file = 'data' + '/' + 'val.csv'\n",
    "train_img_dir = 'data' + '/' + 'train/'\n",
    "validation_img_dir = 'data' + '/' + 'val/'\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = Plain_Dataset(csv_file=traincsv_file, img_dir=train_img_dir, datatype='train', transform=transformation)\n",
    "validation_dataset = Plain_Dataset(csv_file=validationcsv_file, img_dir=validation_img_dir, datatype='val', transform=transformation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Check the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    if num_gpus > 1:\n",
    "        # Set the desired GPU index\n",
    "        gpu_index = 1  # Replace with the index of your desired GPU\n",
    "\n",
    "        if gpu_index >= num_gpus:\n",
    "            raise ValueError(\"Invalid GPU index. Available indices: 0 to {}\".format(num_gpus - 1))\n",
    "\n",
    "        # Set the GPU device to use\n",
    "        torch.cuda.set_device(gpu_index)\n",
    "\n",
    "        # Set GPU power limit to 70% using nvidia-smi command\n",
    "        gpu_device = torch.cuda.current_device()\n",
    "        gpu_power_limit = int(0.7 * torch.cuda.get_device_properties(gpu_device).total_memory)\n",
    "        subprocess.run(['nvidia-smi', '-i', str(gpu_device), '-pl', str(gpu_power_limit)])\n",
    "\n",
    "    else:\n",
    "        # If only one GPU is available, use it\n",
    "        torch.cuda.set_device(0)\n",
    "else:\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "\n",
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validate the model #\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss = validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "epochs = 3200\n",
    "lr = 0.8\n",
    "batchsize = 128\n",
    "\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model architecture: \", net)\n",
    "traincsv_file = 'data' + '/' + 'train.csv'\n",
    "validationcsv_file = 'data' + '/' + 'val.csv'\n",
    "train_img_dir = 'data' + '/' + 'train/'\n",
    "validation_img_dir = 'data' + '/' + 'val/'\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = Plain_Dataset(csv_file=traincsv_file, img_dir=train_img_dir, datatype='train', transform=transformation)\n",
    "validation_dataset = Plain_Dataset(csv_file=validationcsv_file, img_dir=validation_img_dir, datatype='val', transform=transformation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e85a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validate the model #\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss = validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "epochs = 3200\n",
    "lr = 0.004\n",
    "batchsize = 128\n",
    "\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model architecture: \", net)\n",
    "traincsv_file = 'data' + '/' + 'train.csv'\n",
    "validationcsv_file = 'data' + '/' + 'val.csv'\n",
    "train_img_dir = 'data' + '/' + 'train/'\n",
    "validation_img_dir = 'data' + '/' + 'val/'\n",
    "\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = Plain_Dataset(csv_file=traincsv_file, img_dir=train_img_dir, datatype='train', transform=transformation)\n",
    "validation_dataset = Plain_Dataset(csv_file=validationcsv_file, img_dir=validation_img_dir, datatype='val', transform=transformation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a46de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'Speaktrum_by_SOVA.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3efb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss =  validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description=\"Configuration of setup and training process\")\n",
    "#     parser.add_argument('-s', '--setup', type=bool, help='setup the dataset for the first time')\n",
    "#     parser.add_argument('-d', '--data', type=str,required= True,\n",
    "#                                help='data folder that contains data files that downloaded from kaggle (train.csv and test.csv)')\n",
    "#     parser.add_argument('-hparams', '--hyperparams', type=bool,\n",
    "#                                help='True when changing the hyperparameters e.g (batch size, LR, num. of epochs)')\n",
    "#     parser.add_argument('-e', '--epochs', type= int, help= 'number of epochs')\n",
    "#     parser.add_argument('-lr', '--learning_rate', type= float, help= 'value of learning rate')\n",
    "#     parser.add_argument('-bs', '--batch_size', type= int, help= 'training/validation batch size')\n",
    "#     parser.add_argument('-t', '--train', type=bool, help='True when training')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     if args.setup :\n",
    "#         generate_dataset = Generate_data(args.data)\n",
    "#         generate_dataset.split_test()\n",
    "#         generate_dataset.save_images('train')\n",
    "#         generate_dataset.save_images('test')\n",
    "#         generate_dataset.save_images('val')\n",
    "\n",
    "#     if args.hyperparams:\n",
    "#         epochs = args.epochs\n",
    "#         lr = args.learning_rate\n",
    "#         batchsize = args.batch_size\n",
    "#     else :\n",
    "epochs = 100\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "#     if args.train:\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model archticture: \", net)\n",
    "traincsv_file = 'data'+'/'+'train.csv'\n",
    "validationcsv_file = 'data'+'/'+'val.csv'\n",
    "train_img_dir = 'data'+'/'+'train/'\n",
    "validation_img_dir = 'data'+'/'+'val/'\n",
    "\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n",
    "validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n",
    "train_loader= DataLoader(train_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "val_loader=   DataLoader(validation_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optmizer= optim.Adam(net.parameters(),lr= lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optmizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'Speaktrum_by_SOVA.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f306551",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define your neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize an instance of your model\n",
    "net = MyModel()\n",
    "\n",
    "# Load pre-trained weights\n",
    "weights_path = 'path/to/your/model/weights.pth'  # Replace with the actual path to your trained model's weights file\n",
    "checkpoint = torch.load(weights_path)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()\n",
    "\n",
    "# Initialize variables for emotion detection stability\n",
    "cooldown_duration = 5  # Cooldown period in frames\n",
    "cooldown_counter = 0\n",
    "prev_prediction = None\n",
    "emotion_buffer = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # Reset emotion status if no face is detected\n",
    "        cooldown_counter = 0\n",
    "        prev_prediction = None\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            emotion_buffer.append(prediction.item())\n",
    "            if len(emotion_buffer) > cooldown_duration:\n",
    "                emotion_buffer.pop(0)\n",
    "\n",
    "            if cooldown_counter == 0 or cooldown_counter >= cooldown_duration:\n",
    "                # Update the displayed emotion if cooldown is over or not started\n",
    "                avg_prediction = np.mean(emotion_buffer)\n",
    "                confidence = torch.max(pred).item()\n",
    "\n",
    "                if confidence > 0.5:  # Confidence threshold for emotion prediction\n",
    "                    if avg_prediction == 0:\n",
    "                        status = \"Angry\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 1:\n",
    "                        status = \"Disgust\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 2:\n",
    "                        status = \"Fear\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 3:\n",
    "                        status = \"Happy\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 4:\n",
    "                        status = \"Sad\"\n",
    "                        color = (0, 0, 255)\n",
    "                    else:\n",
    "                        status = \"\"\n",
    "                        color = (255, 0, 0)\n",
    "\n",
    "                    x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "                    cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "                    cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "                    prev_prediction = avg_prediction\n",
    "                    cooldown_counter = 0\n",
    "                else:\n",
    "                    cooldown_counter += 1\n",
    "            else:\n",
    "                cooldown_counter += 1\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca58d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6eca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff372840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define your neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize an instance of your model\n",
    "net = MyModel()\n",
    "\n",
    "# Load pre-trained weights\n",
    "weights_path = 'path/to/your/model/weights.pth'  # Replace with the actual path to your trained model's weights file\n",
    "checkpoint = torch.load(weights_path)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()\n",
    "\n",
    "# Initialize variables for emotion detection stability\n",
    "cooldown_duration = 5  # Cooldown period in frames\n",
    "cooldown_counter = 0\n",
    "prev_prediction = None\n",
    "emotion_buffer = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # Reset emotion status if no face is detected\n",
    "        cooldown_counter = 0\n",
    "        prev_prediction = None\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            emotion_buffer.append(prediction.item())\n",
    "            if len(emotion_buffer) > cooldown_duration:\n",
    "                emotion_buffer.pop(0)\n",
    "\n",
    "            if cooldown_counter == 0 or cooldown_counter >= cooldown_duration:\n",
    "                # Update the displayed emotion if cooldown is over or not started\n",
    "                avg_prediction = np.mean(emotion_buffer)\n",
    "                confidence = torch.max(pred).item()\n",
    "\n",
    "                if confidence > 0.5:  # Confidence threshold for emotion prediction\n",
    "                    if avg_prediction == 0:\n",
    "                        status = \"Angry\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 1:\n",
    "                        status = \"Disgust\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 2:\n",
    "                        status = \"Fear\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 3:\n",
    "                        status = \"Happy\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 4:\n",
    "                        status = \"Sad\"\n",
    "                        color = (0, 0, 255)\n",
    "                    else:\n",
    "                        status = \"\"\n",
    "                        color = (255, 0, 0)\n",
    "\n",
    "                    x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "                    cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "                    cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "                    prev_prediction = avg_prediction\n",
    "                    cooldown_counter = 0\n",
    "                else:\n",
    "                    cooldown_counter += 1\n",
    "            else:\n",
    "                cooldown_counter += 1\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define your neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize an instance of your model\n",
    "net = MyModel()\n",
    "\n",
    "# Load pre-trained weights\n",
    "weights_path = 'path/to/your/model/weights.pth'  # Replace with the actual path to your trained model's weights file\n",
    "checkpoint = torch.load(weights_path, map_location=device)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "# Initialize variables for emotion detection stability\n",
    "cooldown_duration = 5  # Cooldown period in frames\n",
    "cooldown_counter = 0\n",
    "prev_prediction = None\n",
    "emotion_buffer = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # Reset emotion status if no face is detected\n",
    "        cooldown_counter = 0\n",
    "        prev_prediction = None\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = net(data)\n",
    "                pred = F.softmax(outputs, dim=1)\n",
    "                prediction = torch.argmax(pred)\n",
    "\n",
    "            emotion_buffer.append(prediction.item())\n",
    "            if len(emotion_buffer) > cooldown_duration:\n",
    "                emotion_buffer.pop(0)\n",
    "\n",
    "            if cooldown_counter == 0 or cooldown_counter >= cooldown_duration:\n",
    "                # Update the displayed emotion if cooldown is over or not started\n",
    "                avg_prediction = np.mean(emotion_buffer)\n",
    "                confidence = torch.max(pred).item()\n",
    "\n",
    "                if confidence > 0.5:  # Confidence threshold for emotion prediction\n",
    "                    if avg_prediction == 0:\n",
    "                        status = \"Angry\"\n",
    "                        color = (0, 0, 255)\n",
    "                    elif avg_prediction == 1:\n",
    "                        status = \"Disgust\"\n",
    "                        color = (0, 255, 0)\n",
    "                    elif avg_prediction == 2:\n",
    "                        status = \"Fear\"\n",
    "                        color = (255, 0, 0)\n",
    "                    elif avg_prediction == 3:\n",
    "                        status = \"Happy\"\n",
    "                        color = (0, 255, 255)\n",
    "                    elif avg_prediction == 4:\n",
    "                        status = \"Sad\"\n",
    "                        color = (255, 0, 255)\n",
    "                    else:\n",
    "                        status = \"\"\n",
    "                        color = (255, 0, 0)\n",
    "\n",
    "                    x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "                    cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "                    cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "                    prev_prediction = avg_prediction\n",
    "                    cooldown_counter = 0\n",
    "                else:\n",
    "                    cooldown_counter += 1\n",
    "            else:\n",
    "                cooldown_counter += 1\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, status, (50, 50), font, 0, color, 2, cv2.LINE_4)\n",
    "    cv2.imshow('Face', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define your neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize an instance of your model\n",
    "net = MyModel()\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "try:\n",
    "    checkpoint = torch.load('weights.pth', map_location=device)\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    weights_loaded = True\n",
    "except FileNotFoundError:\n",
    "    weights_loaded = False\n",
    "    print(\"No pre-trained weights found. Please train your model or provide the weights file.\")\n",
    "\n",
    "# Initialize variables for emotion detection stability\n",
    "cooldown_duration = 5  # Cooldown period in frames\n",
    "cooldown_counter = 0\n",
    "prev_prediction = None\n",
    "emotion_buffer = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # Reset emotion status if no face is detected\n",
    "        cooldown_counter = 0\n",
    "        prev_prediction = None\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            if weights_loaded:\n",
    "                outputs = net(data)\n",
    "                pred = F.softmax(outputs, dim=1)\n",
    "                prediction = torch.argmax(pred)\n",
    "\n",
    "                emotion_buffer.append(prediction.item())\n",
    "                if len(emotion_buffer) > cooldown_duration:\n",
    "                    emotion_buffer.pop(0)\n",
    "\n",
    "                if cooldown_counter == 0 or cooldown_counter >= cooldown_duration:\n",
    "                    # Update the displayed emotion if cooldown is over or not started\n",
    "                    avg_prediction = np.mean(emotion_buffer)\n",
    "                    confidence = torch.max(pred).item()\n",
    "\n",
    "                    if confidence > 0.5:  # Confidence threshold for emotion prediction\n",
    "                        if avg_prediction == 0:\n",
    "                            status = \"Angry\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 1:\n",
    "                            status = \"Disgust\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 2:\n",
    "                            status = \"Fear\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 3:\n",
    "                            status = \"Happy\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 4:\n",
    "                            status = \"Sad\"\n",
    "                            color = (0, 0, 255)\n",
    "                        else:\n",
    "                            status = \"\"\n",
    "                            color = (255, 0, 0)\n",
    "\n",
    "                        x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "                        cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "                        cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                        cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "                        prev_prediction = avg_prediction\n",
    "                        cooldown_counter = 0\n",
    "                    else:\n",
    "                        cooldown_counter += 1\n",
    "                else:\n",
    "                    cooldown_counter += 1\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame,\n",
    "                        status,\n",
    "                        (50, 50),\n",
    "                        font, 0,\n",
    "                        color,\n",
    "                        2,\n",
    "                        cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa93424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = MyModel()  # Replace MyModel with your actual model class\n",
    "net.load_state_dict(torch.load('path_to_your_model_weights.pth'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define your neural network model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize an instance of your model\n",
    "net = MyModel()\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "try:\n",
    "    checkpoint = torch.load('weights.pth', map_location=device)\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    weights_loaded = True\n",
    "except FileNotFoundError:\n",
    "    weights_loaded = False\n",
    "    print(\"No pre-trained weights found. Please train your model or provide the weights file.\")\n",
    "\n",
    "# Initialize variables for emotion detection stability\n",
    "cooldown_duration = 5  # Cooldown period in frames\n",
    "cooldown_counter = 0\n",
    "prev_prediction = None\n",
    "emotion_buffer = []\n",
    "\n",
    "status = \"\"  # Initialize status variable\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        # Reset emotion status if no face is detected\n",
    "        cooldown_counter = 0\n",
    "        prev_prediction = None\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            if weights_loaded:\n",
    "                outputs = net(data)\n",
    "                pred = F.softmax(outputs, dim=1)\n",
    "                prediction = torch.argmax(pred)\n",
    "\n",
    "                emotion_buffer.append(prediction.item())\n",
    "                if len(emotion_buffer) > cooldown_duration:\n",
    "                    emotion_buffer.pop(0)\n",
    "\n",
    "                if cooldown_counter == 0 or cooldown_counter >= cooldown_duration:\n",
    "                    # Update the displayed emotion if cooldown is over or not started\n",
    "                    avg_prediction = np.mean(emotion_buffer)\n",
    "                    confidence = torch.max(pred).item()\n",
    "\n",
    "                    if confidence > 0.5:  # Confidence threshold for emotion prediction\n",
    "                        if avg_prediction == 0:\n",
    "                            status = \"Angry\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 1:\n",
    "                            status = \"Disgust\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 2:\n",
    "                            status = \"Fear\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 3:\n",
    "                            status = \"Happy\"\n",
    "                            color = (0, 0, 255)\n",
    "                        elif avg_prediction == 4:\n",
    "                            status = \"Sad\"\n",
    "                            color = (0, 0, 255)\n",
    "                        else:\n",
    "                            status = \"\"\n",
    "                            color = (255, 0, 0)\n",
    "\n",
    "                        x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "                        cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "                        cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                        cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "                        prev_prediction = avg_prediction\n",
    "                        cooldown_counter = 0\n",
    "                    else:\n",
    "                        cooldown_counter += 1\n",
    "                else:\n",
    "                    cooldown_counter += 1\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame,\n",
    "                        status,\n",
    "                        (50, 50),\n",
    "                        font, 0,\n",
    "                        color,\n",
    "                        2,\n",
    "                        cv2.LINE_4)\n",
    "    cv2.imshow('Face', frame)\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss =  validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description=\"Configuration of setup and training process\")\n",
    "#     parser.add_argument('-s', '--setup', type=bool, help='setup the dataset for the first time')\n",
    "#     parser.add_argument('-d', '--data', type=str,required= True,\n",
    "#                                help='data folder that contains data files that downloaded from kaggle (train.csv and test.csv)')\n",
    "#     parser.add_argument('-hparams', '--hyperparams', type=bool,\n",
    "#                                help='True when changing the hyperparameters e.g (batch size, LR, num. of epochs)')\n",
    "#     parser.add_argument('-e', '--epochs', type= int, help= 'number of epochs')\n",
    "#     parser.add_argument('-lr', '--learning_rate', type= float, help= 'value of learning rate')\n",
    "#     parser.add_argument('-bs', '--batch_size', type= int, help= 'training/validation batch size')\n",
    "#     parser.add_argument('-t', '--train', type=bool, help='True when training')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     if args.setup :\n",
    "#         generate_dataset = Generate_data(args.data)\n",
    "#         generate_dataset.split_test()\n",
    "#         generate_dataset.save_images('train')\n",
    "#         generate_dataset.save_images('test')\n",
    "#         generate_dataset.save_images('val')\n",
    "\n",
    "#     if args.hyperparams:\n",
    "#         epochs = args.epochs\n",
    "#         lr = args.learning_rate\n",
    "#         batchsize = args.batch_size\n",
    "#     else :\n",
    "epochs = 100\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "#     if args.train:\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model archticture: \", net)\n",
    "traincsv_file = 'data'+'/'+'train.csv'\n",
    "validationcsv_file = 'data'+'/'+'val.csv'\n",
    "train_img_dir = 'data'+'/'+'train/'\n",
    "validation_img_dir = 'data'+'/'+'val/'\n",
    "\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n",
    "validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n",
    "train_loader= DataLoader(train_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "val_loader=   DataLoader(validation_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optmizer= optim.Adam(net.parameters(),lr= lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optmizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af256cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'Speaktrum_by_SOVA.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e022454",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa653e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843800c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model archticture:  Deep_Emotion(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=810, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=7, bias=True)\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "===================================Start Training===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:4277: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:4215: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.01435391 \tValidation Loss 0.01487185 \tTraining Acuuarcy 24.523% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 2 \tTraining Loss: 0.01426187 \tValidation Loss 0.01484136 \tTraining Acuuarcy 25.053% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 3 \tTraining Loss: 0.01424593 \tValidation Loss 0.01469877 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 4 \tTraining Loss: 0.01423301 \tValidation Loss 0.01473601 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 5 \tTraining Loss: 0.01423396 \tValidation Loss 0.01476917 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 6 \tTraining Loss: 0.01422309 \tValidation Loss 0.01482112 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 7 \tTraining Loss: 0.01422252 \tValidation Loss 0.01470073 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 8 \tTraining Loss: 0.01421308 \tValidation Loss 0.01470265 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 9 \tTraining Loss: 0.01421781 \tValidation Loss 0.01478148 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 10 \tTraining Loss: 0.01424035 \tValidation Loss 0.01473425 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 11 \tTraining Loss: 0.01420713 \tValidation Loss 0.01474546 \tTraining Acuuarcy 25.042% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 12 \tTraining Loss: 0.01420683 \tValidation Loss 0.01475252 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 13 \tTraining Loss: 0.01420473 \tValidation Loss 0.01473825 \tTraining Acuuarcy 25.042% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 14 \tTraining Loss: 0.01420187 \tValidation Loss 0.01476724 \tTraining Acuuarcy 25.059% \tValidation Acuuarcy 25.160%\n",
      "Epoch: 15 \tTraining Loss: 0.01421250 \tValidation Loss 0.01499525 \tTraining Acuuarcy 25.059% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 16 \tTraining Loss: 0.01419281 \tValidation Loss 0.01471300 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 17 \tTraining Loss: 0.01419862 \tValidation Loss 0.01486849 \tTraining Acuuarcy 25.036% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 18 \tTraining Loss: 0.01419905 \tValidation Loss 0.01466150 \tTraining Acuuarcy 24.908% \tValidation Acuuarcy 25.188%\n",
      "Epoch: 19 \tTraining Loss: 0.01418923 \tValidation Loss 0.01467110 \tTraining Acuuarcy 25.053% \tValidation Acuuarcy 25.132%\n",
      "Epoch: 20 \tTraining Loss: 0.01419153 \tValidation Loss 0.01486520 \tTraining Acuuarcy 25.053% \tValidation Acuuarcy 25.021%\n",
      "Epoch: 21 \tTraining Loss: 0.01420233 \tValidation Loss 0.01469548 \tTraining Acuuarcy 25.036% \tValidation Acuuarcy 25.188%\n",
      "Epoch: 22 \tTraining Loss: 0.01419232 \tValidation Loss 0.01471512 \tTraining Acuuarcy 25.109% \tValidation Acuuarcy 25.049%\n",
      "Epoch: 23 \tTraining Loss: 0.01417147 \tValidation Loss 0.01476322 \tTraining Acuuarcy 25.137% \tValidation Acuuarcy 24.519%\n",
      "Epoch: 24 \tTraining Loss: 0.01417853 \tValidation Loss 0.01473047 \tTraining Acuuarcy 24.975% \tValidation Acuuarcy 24.993%\n",
      "Epoch: 25 \tTraining Loss: 0.01416388 \tValidation Loss 0.01476783 \tTraining Acuuarcy 25.053% \tValidation Acuuarcy 25.272%\n",
      "Epoch: 26 \tTraining Loss: 0.01416137 \tValidation Loss 0.01479049 \tTraining Acuuarcy 25.047% \tValidation Acuuarcy 25.077%\n",
      "Epoch: 27 \tTraining Loss: 0.01415115 \tValidation Loss 0.01474252 \tTraining Acuuarcy 25.114% \tValidation Acuuarcy 24.547%\n",
      "Epoch: 28 \tTraining Loss: 0.01414887 \tValidation Loss 0.01478605 \tTraining Acuuarcy 25.226% \tValidation Acuuarcy 24.436%\n",
      "Epoch: 29 \tTraining Loss: 0.01414364 \tValidation Loss 0.01485550 \tTraining Acuuarcy 25.164% \tValidation Acuuarcy 25.021%\n",
      "Epoch: 30 \tTraining Loss: 0.01415543 \tValidation Loss 0.01475070 \tTraining Acuuarcy 25.315% \tValidation Acuuarcy 25.216%\n",
      "Epoch: 31 \tTraining Loss: 0.01416317 \tValidation Loss 0.01501603 \tTraining Acuuarcy 25.231% \tValidation Acuuarcy 25.160%\n",
      "Epoch: 32 \tTraining Loss: 0.01413929 \tValidation Loss 0.01482743 \tTraining Acuuarcy 25.287% \tValidation Acuuarcy 24.854%\n",
      "Epoch: 33 \tTraining Loss: 0.01410200 \tValidation Loss 0.01487916 \tTraining Acuuarcy 25.242% \tValidation Acuuarcy 24.909%\n",
      "Epoch: 34 \tTraining Loss: 0.01411138 \tValidation Loss 0.01485826 \tTraining Acuuarcy 25.254% \tValidation Acuuarcy 24.380%\n",
      "Epoch: 35 \tTraining Loss: 0.01410946 \tValidation Loss 0.01484816 \tTraining Acuuarcy 25.376% \tValidation Acuuarcy 25.021%\n",
      "Epoch: 36 \tTraining Loss: 0.01408817 \tValidation Loss 0.01487147 \tTraining Acuuarcy 25.772% \tValidation Acuuarcy 24.436%\n",
      "Epoch: 37 \tTraining Loss: 0.01411301 \tValidation Loss 0.01490477 \tTraining Acuuarcy 25.176% \tValidation Acuuarcy 24.603%\n",
      "Epoch: 38 \tTraining Loss: 0.01408544 \tValidation Loss 0.01488073 \tTraining Acuuarcy 25.477% \tValidation Acuuarcy 24.714%\n",
      "Epoch: 39 \tTraining Loss: 0.01408048 \tValidation Loss 0.01484469 \tTraining Acuuarcy 25.549% \tValidation Acuuarcy 24.547%\n",
      "Epoch: 40 \tTraining Loss: 0.01406904 \tValidation Loss 0.01486646 \tTraining Acuuarcy 25.504% \tValidation Acuuarcy 24.380%\n",
      "Epoch: 41 \tTraining Loss: 0.01405834 \tValidation Loss 0.01488954 \tTraining Acuuarcy 25.582% \tValidation Acuuarcy 24.937%\n",
      "Epoch: 42 \tTraining Loss: 0.01405357 \tValidation Loss 0.01492876 \tTraining Acuuarcy 25.778% \tValidation Acuuarcy 24.213%\n",
      "Epoch: 43 \tTraining Loss: 0.01405450 \tValidation Loss 0.01499095 \tTraining Acuuarcy 25.822% \tValidation Acuuarcy 23.851%\n",
      "Epoch: 44 \tTraining Loss: 0.01404578 \tValidation Loss 0.01484691 \tTraining Acuuarcy 25.694% \tValidation Acuuarcy 24.074%\n",
      "Epoch: 45 \tTraining Loss: 0.01402997 \tValidation Loss 0.01487904 \tTraining Acuuarcy 26.112% \tValidation Acuuarcy 24.269%\n",
      "Epoch: 46 \tTraining Loss: 0.01400791 \tValidation Loss 0.01495647 \tTraining Acuuarcy 26.162% \tValidation Acuuarcy 24.185%\n",
      "Epoch: 47 \tTraining Loss: 0.01402914 \tValidation Loss 0.01493946 \tTraining Acuuarcy 26.151% \tValidation Acuuarcy 24.519%\n",
      "Epoch: 48 \tTraining Loss: 0.01399908 \tValidation Loss 0.01492369 \tTraining Acuuarcy 25.995% \tValidation Acuuarcy 23.823%\n",
      "Epoch: 49 \tTraining Loss: 0.01399548 \tValidation Loss 0.01498426 \tTraining Acuuarcy 26.090% \tValidation Acuuarcy 24.492%\n",
      "Epoch: 50 \tTraining Loss: 0.01398253 \tValidation Loss 0.01496383 \tTraining Acuuarcy 26.251% \tValidation Acuuarcy 24.046%\n",
      "Epoch: 51 \tTraining Loss: 0.01397011 \tValidation Loss 0.01500513 \tTraining Acuuarcy 26.418% \tValidation Acuuarcy 23.070%\n",
      "Epoch: 52 \tTraining Loss: 0.01396270 \tValidation Loss 0.01505374 \tTraining Acuuarcy 26.201% \tValidation Acuuarcy 24.408%\n",
      "Epoch: 53 \tTraining Loss: 0.01394932 \tValidation Loss 0.01497485 \tTraining Acuuarcy 26.831% \tValidation Acuuarcy 24.241%\n",
      "Epoch: 54 \tTraining Loss: 0.01394340 \tValidation Loss 0.01513073 \tTraining Acuuarcy 26.630% \tValidation Acuuarcy 23.739%\n",
      "Epoch: 55 \tTraining Loss: 0.01392352 \tValidation Loss 0.01498417 \tTraining Acuuarcy 26.809% \tValidation Acuuarcy 24.603%\n",
      "Epoch: 56 \tTraining Loss: 0.01391819 \tValidation Loss 0.01495445 \tTraining Acuuarcy 26.536% \tValidation Acuuarcy 24.157%\n",
      "Epoch: 57 \tTraining Loss: 0.01393369 \tValidation Loss 0.01515559 \tTraining Acuuarcy 26.714% \tValidation Acuuarcy 23.851%\n",
      "Epoch: 58 \tTraining Loss: 0.01389688 \tValidation Loss 0.01533260 \tTraining Acuuarcy 26.541% \tValidation Acuuarcy 23.683%\n",
      "Epoch: 59 \tTraining Loss: 0.01390529 \tValidation Loss 0.01499129 \tTraining Acuuarcy 26.892% \tValidation Acuuarcy 23.238%\n",
      "Epoch: 60 \tTraining Loss: 0.01387533 \tValidation Loss 0.01517761 \tTraining Acuuarcy 27.160% \tValidation Acuuarcy 24.046%\n",
      "Epoch: 61 \tTraining Loss: 0.01384912 \tValidation Loss 0.01512231 \tTraining Acuuarcy 26.959% \tValidation Acuuarcy 23.851%\n",
      "Epoch: 62 \tTraining Loss: 0.01384441 \tValidation Loss 0.01519100 \tTraining Acuuarcy 27.394% \tValidation Acuuarcy 23.293%\n",
      "Epoch: 63 \tTraining Loss: 0.01387645 \tValidation Loss 0.01513716 \tTraining Acuuarcy 27.110% \tValidation Acuuarcy 23.238%\n",
      "Epoch: 64 \tTraining Loss: 0.01382307 \tValidation Loss 0.01506513 \tTraining Acuuarcy 26.809% \tValidation Acuuarcy 23.795%\n",
      "Epoch: 65 \tTraining Loss: 0.01386115 \tValidation Loss 0.01512583 \tTraining Acuuarcy 27.199% \tValidation Acuuarcy 23.683%\n",
      "Epoch: 66 \tTraining Loss: 0.01381459 \tValidation Loss 0.01505564 \tTraining Acuuarcy 27.723% \tValidation Acuuarcy 23.433%\n",
      "Epoch: 67 \tTraining Loss: 0.01382873 \tValidation Loss 0.01522137 \tTraining Acuuarcy 27.594% \tValidation Acuuarcy 23.544%\n",
      "Epoch: 68 \tTraining Loss: 0.01379352 \tValidation Loss 0.01542489 \tTraining Acuuarcy 27.823% \tValidation Acuuarcy 22.792%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 \tTraining Loss: 0.01383214 \tValidation Loss 0.01520483 \tTraining Acuuarcy 27.199% \tValidation Acuuarcy 25.104%\n",
      "Epoch: 70 \tTraining Loss: 0.01376612 \tValidation Loss 0.01526672 \tTraining Acuuarcy 27.628% \tValidation Acuuarcy 23.544%\n",
      "Epoch: 71 \tTraining Loss: 0.01378001 \tValidation Loss 0.01509780 \tTraining Acuuarcy 27.360% \tValidation Acuuarcy 23.851%\n",
      "Epoch: 72 \tTraining Loss: 0.01379991 \tValidation Loss 0.01515619 \tTraining Acuuarcy 27.594% \tValidation Acuuarcy 23.126%\n",
      "Epoch: 73 \tTraining Loss: 0.01381174 \tValidation Loss 0.01518723 \tTraining Acuuarcy 27.639% \tValidation Acuuarcy 24.324%\n",
      "Epoch: 74 \tTraining Loss: 0.01376695 \tValidation Loss 0.01537027 \tTraining Acuuarcy 27.700% \tValidation Acuuarcy 22.792%\n",
      "Epoch: 75 \tTraining Loss: 0.01376535 \tValidation Loss 0.01519289 \tTraining Acuuarcy 27.862% \tValidation Acuuarcy 23.823%\n",
      "Epoch: 76 \tTraining Loss: 0.01373057 \tValidation Loss 0.01527421 \tTraining Acuuarcy 27.873% \tValidation Acuuarcy 23.015%\n",
      "Epoch: 77 \tTraining Loss: 0.01373374 \tValidation Loss 0.01515973 \tTraining Acuuarcy 28.196% \tValidation Acuuarcy 24.074%\n",
      "Epoch: 78 \tTraining Loss: 0.01372874 \tValidation Loss 0.01525864 \tTraining Acuuarcy 27.907% \tValidation Acuuarcy 22.875%\n",
      "Epoch: 79 \tTraining Loss: 0.01374437 \tValidation Loss 0.01538885 \tTraining Acuuarcy 28.135% \tValidation Acuuarcy 22.959%\n",
      "Epoch: 80 \tTraining Loss: 0.01370705 \tValidation Loss 0.01548282 \tTraining Acuuarcy 28.308% \tValidation Acuuarcy 22.903%\n",
      "Epoch: 81 \tTraining Loss: 0.01372137 \tValidation Loss 0.01545191 \tTraining Acuuarcy 27.840% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 82 \tTraining Loss: 0.01371894 \tValidation Loss 0.01550298 \tTraining Acuuarcy 28.224% \tValidation Acuuarcy 23.182%\n",
      "Epoch: 83 \tTraining Loss: 0.01371365 \tValidation Loss 0.01528870 \tTraining Acuuarcy 28.163% \tValidation Acuuarcy 23.266%\n",
      "Epoch: 84 \tTraining Loss: 0.01367600 \tValidation Loss 0.01516737 \tTraining Acuuarcy 28.453% \tValidation Acuuarcy 23.795%\n",
      "Epoch: 85 \tTraining Loss: 0.01367314 \tValidation Loss 0.01524559 \tTraining Acuuarcy 28.497% \tValidation Acuuarcy 23.433%\n",
      "Epoch: 86 \tTraining Loss: 0.01367127 \tValidation Loss 0.01547863 \tTraining Acuuarcy 28.263% \tValidation Acuuarcy 22.903%\n",
      "Epoch: 87 \tTraining Loss: 0.01365452 \tValidation Loss 0.01540971 \tTraining Acuuarcy 28.503% \tValidation Acuuarcy 22.290%\n",
      "Epoch: 88 \tTraining Loss: 0.01369025 \tValidation Loss 0.01522936 \tTraining Acuuarcy 28.509% \tValidation Acuuarcy 23.098%\n",
      "Epoch: 89 \tTraining Loss: 0.01364116 \tValidation Loss 0.01559503 \tTraining Acuuarcy 28.531% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 90 \tTraining Loss: 0.01363652 \tValidation Loss 0.01539688 \tTraining Acuuarcy 28.575% \tValidation Acuuarcy 23.656%\n",
      "Epoch: 91 \tTraining Loss: 0.01363396 \tValidation Loss 0.01552213 \tTraining Acuuarcy 28.648% \tValidation Acuuarcy 23.934%\n",
      "Epoch: 92 \tTraining Loss: 0.01359304 \tValidation Loss 0.01543871 \tTraining Acuuarcy 29.200% \tValidation Acuuarcy 22.931%\n",
      "Epoch: 93 \tTraining Loss: 0.01366183 \tValidation Loss 0.01524945 \tTraining Acuuarcy 28.631% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 94 \tTraining Loss: 0.01360927 \tValidation Loss 0.01545596 \tTraining Acuuarcy 29.272% \tValidation Acuuarcy 22.792%\n",
      "Epoch: 95 \tTraining Loss: 0.01358450 \tValidation Loss 0.01553065 \tTraining Acuuarcy 28.681% \tValidation Acuuarcy 21.845%\n",
      "Epoch: 96 \tTraining Loss: 0.01359201 \tValidation Loss 0.01553127 \tTraining Acuuarcy 29.166% \tValidation Acuuarcy 22.597%\n",
      "Epoch: 97 \tTraining Loss: 0.01359848 \tValidation Loss 0.01562377 \tTraining Acuuarcy 28.832% \tValidation Acuuarcy 22.374%\n",
      "Epoch: 98 \tTraining Loss: 0.01360927 \tValidation Loss 0.01540549 \tTraining Acuuarcy 28.821% \tValidation Acuuarcy 24.157%\n",
      "Epoch: 99 \tTraining Loss: 0.01356299 \tValidation Loss 0.01562091 \tTraining Acuuarcy 29.512% \tValidation Acuuarcy 22.597%\n",
      "Epoch: 100 \tTraining Loss: 0.01357111 \tValidation Loss 0.01544280 \tTraining Acuuarcy 29.094% \tValidation Acuuarcy 23.070%\n",
      "Epoch: 101 \tTraining Loss: 0.01358947 \tValidation Loss 0.01589513 \tTraining Acuuarcy 29.077% \tValidation Acuuarcy 22.931%\n",
      "Epoch: 102 \tTraining Loss: 0.01356379 \tValidation Loss 0.01541739 \tTraining Acuuarcy 29.434% \tValidation Acuuarcy 23.126%\n",
      "Epoch: 103 \tTraining Loss: 0.01355400 \tValidation Loss 0.01562997 \tTraining Acuuarcy 29.484% \tValidation Acuuarcy 22.903%\n",
      "Epoch: 104 \tTraining Loss: 0.01353444 \tValidation Loss 0.01561243 \tTraining Acuuarcy 29.283% \tValidation Acuuarcy 22.959%\n",
      "Epoch: 105 \tTraining Loss: 0.01354781 \tValidation Loss 0.01544645 \tTraining Acuuarcy 29.183% \tValidation Acuuarcy 22.207%\n",
      "Epoch: 106 \tTraining Loss: 0.01357882 \tValidation Loss 0.01566730 \tTraining Acuuarcy 29.172% \tValidation Acuuarcy 21.984%\n",
      "Epoch: 107 \tTraining Loss: 0.01353858 \tValidation Loss 0.01558466 \tTraining Acuuarcy 29.417% \tValidation Acuuarcy 23.098%\n",
      "Epoch: 108 \tTraining Loss: 0.01355068 \tValidation Loss 0.01567473 \tTraining Acuuarcy 29.306% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 109 \tTraining Loss: 0.01350617 \tValidation Loss 0.01542143 \tTraining Acuuarcy 29.155% \tValidation Acuuarcy 23.070%\n",
      "Epoch: 110 \tTraining Loss: 0.01352500 \tValidation Loss 0.01555119 \tTraining Acuuarcy 29.417% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 111 \tTraining Loss: 0.01351692 \tValidation Loss 0.01550394 \tTraining Acuuarcy 29.389% \tValidation Acuuarcy 23.070%\n",
      "Epoch: 112 \tTraining Loss: 0.01350150 \tValidation Loss 0.01560524 \tTraining Acuuarcy 29.590% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 113 \tTraining Loss: 0.01351653 \tValidation Loss 0.01577840 \tTraining Acuuarcy 29.567% \tValidation Acuuarcy 23.070%\n",
      "Epoch: 114 \tTraining Loss: 0.01351646 \tValidation Loss 0.01550382 \tTraining Acuuarcy 29.768% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 115 \tTraining Loss: 0.01349230 \tValidation Loss 0.01541220 \tTraining Acuuarcy 29.545% \tValidation Acuuarcy 22.402%\n",
      "Epoch: 116 \tTraining Loss: 0.01349112 \tValidation Loss 0.01549551 \tTraining Acuuarcy 29.339% \tValidation Acuuarcy 23.321%\n",
      "Epoch: 117 \tTraining Loss: 0.01349100 \tValidation Loss 0.01576307 \tTraining Acuuarcy 29.991% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 118 \tTraining Loss: 0.01346907 \tValidation Loss 0.01550932 \tTraining Acuuarcy 29.874% \tValidation Acuuarcy 21.928%\n",
      "Epoch: 119 \tTraining Loss: 0.01346455 \tValidation Loss 0.01575040 \tTraining Acuuarcy 29.718% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 120 \tTraining Loss: 0.01341430 \tValidation Loss 0.01570324 \tTraining Acuuarcy 30.114% \tValidation Acuuarcy 22.262%\n",
      "Epoch: 121 \tTraining Loss: 0.01347643 \tValidation Loss 0.01583367 \tTraining Acuuarcy 29.941% \tValidation Acuuarcy 22.290%\n",
      "Epoch: 122 \tTraining Loss: 0.01345214 \tValidation Loss 0.01566016 \tTraining Acuuarcy 30.136% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 123 \tTraining Loss: 0.01347960 \tValidation Loss 0.01561184 \tTraining Acuuarcy 29.740% \tValidation Acuuarcy 23.043%\n",
      "Epoch: 124 \tTraining Loss: 0.01342427 \tValidation Loss 0.01572281 \tTraining Acuuarcy 29.718% \tValidation Acuuarcy 22.680%\n",
      "Epoch: 125 \tTraining Loss: 0.01342814 \tValidation Loss 0.01592579 \tTraining Acuuarcy 30.231% \tValidation Acuuarcy 22.987%\n",
      "Epoch: 126 \tTraining Loss: 0.01339269 \tValidation Loss 0.01569959 \tTraining Acuuarcy 30.454% \tValidation Acuuarcy 22.123%\n",
      "Epoch: 127 \tTraining Loss: 0.01342324 \tValidation Loss 0.01554780 \tTraining Acuuarcy 29.863% \tValidation Acuuarcy 23.098%\n",
      "Epoch: 128 \tTraining Loss: 0.01343626 \tValidation Loss 0.01552354 \tTraining Acuuarcy 30.136% \tValidation Acuuarcy 23.377%\n",
      "Epoch: 129 \tTraining Loss: 0.01341299 \tValidation Loss 0.01556096 \tTraining Acuuarcy 29.958% \tValidation Acuuarcy 23.433%\n",
      "Epoch: 130 \tTraining Loss: 0.01342188 \tValidation Loss 0.01581768 \tTraining Acuuarcy 29.868% \tValidation Acuuarcy 21.900%\n",
      "Epoch: 131 \tTraining Loss: 0.01336745 \tValidation Loss 0.01559894 \tTraining Acuuarcy 30.470% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 132 \tTraining Loss: 0.01342017 \tValidation Loss 0.01601607 \tTraining Acuuarcy 29.874% \tValidation Acuuarcy 22.179%\n",
      "Epoch: 133 \tTraining Loss: 0.01344111 \tValidation Loss 0.01564480 \tTraining Acuuarcy 30.320% \tValidation Acuuarcy 23.628%\n",
      "Epoch: 134 \tTraining Loss: 0.01339581 \tValidation Loss 0.01573001 \tTraining Acuuarcy 30.398% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 135 \tTraining Loss: 0.01339706 \tValidation Loss 0.01565355 \tTraining Acuuarcy 30.064% \tValidation Acuuarcy 22.903%\n",
      "Epoch: 136 \tTraining Loss: 0.01336063 \tValidation Loss 0.01597292 \tTraining Acuuarcy 30.292% \tValidation Acuuarcy 22.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137 \tTraining Loss: 0.01342235 \tValidation Loss 0.01571160 \tTraining Acuuarcy 29.868% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 138 \tTraining Loss: 0.01337734 \tValidation Loss 0.01593142 \tTraining Acuuarcy 30.493% \tValidation Acuuarcy 22.485%\n",
      "Epoch: 139 \tTraining Loss: 0.01338330 \tValidation Loss 0.01585406 \tTraining Acuuarcy 30.409% \tValidation Acuuarcy 22.458%\n",
      "Epoch: 140 \tTraining Loss: 0.01338816 \tValidation Loss 0.01569390 \tTraining Acuuarcy 30.415% \tValidation Acuuarcy 23.795%\n",
      "Epoch: 141 \tTraining Loss: 0.01338812 \tValidation Loss 0.01570484 \tTraining Acuuarcy 30.270% \tValidation Acuuarcy 21.789%\n",
      "Epoch: 142 \tTraining Loss: 0.01341645 \tValidation Loss 0.01570315 \tTraining Acuuarcy 30.398% \tValidation Acuuarcy 23.293%\n",
      "Epoch: 143 \tTraining Loss: 0.01333258 \tValidation Loss 0.01574283 \tTraining Acuuarcy 30.314% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 144 \tTraining Loss: 0.01333614 \tValidation Loss 0.01585368 \tTraining Acuuarcy 30.610% \tValidation Acuuarcy 22.708%\n",
      "Epoch: 145 \tTraining Loss: 0.01335650 \tValidation Loss 0.01577592 \tTraining Acuuarcy 30.599% \tValidation Acuuarcy 23.126%\n",
      "Epoch: 146 \tTraining Loss: 0.01333564 \tValidation Loss 0.01577330 \tTraining Acuuarcy 30.548% \tValidation Acuuarcy 21.928%\n",
      "Epoch: 147 \tTraining Loss: 0.01333808 \tValidation Loss 0.01589158 \tTraining Acuuarcy 30.515% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 148 \tTraining Loss: 0.01332947 \tValidation Loss 0.01588101 \tTraining Acuuarcy 30.599% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 149 \tTraining Loss: 0.01336106 \tValidation Loss 0.01584946 \tTraining Acuuarcy 30.699% \tValidation Acuuarcy 22.179%\n",
      "Epoch: 150 \tTraining Loss: 0.01336950 \tValidation Loss 0.01575343 \tTraining Acuuarcy 30.404% \tValidation Acuuarcy 22.820%\n",
      "Epoch: 151 \tTraining Loss: 0.01332026 \tValidation Loss 0.01575396 \tTraining Acuuarcy 30.632% \tValidation Acuuarcy 22.374%\n",
      "Epoch: 152 \tTraining Loss: 0.01335065 \tValidation Loss 0.01585025 \tTraining Acuuarcy 30.744% \tValidation Acuuarcy 22.625%\n",
      "Epoch: 153 \tTraining Loss: 0.01334693 \tValidation Loss 0.01590063 \tTraining Acuuarcy 30.370% \tValidation Acuuarcy 22.848%\n",
      "Epoch: 154 \tTraining Loss: 0.01336347 \tValidation Loss 0.01586968 \tTraining Acuuarcy 30.593% \tValidation Acuuarcy 22.374%\n",
      "Epoch: 155 \tTraining Loss: 0.01332092 \tValidation Loss 0.01585732 \tTraining Acuuarcy 31.089% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 156 \tTraining Loss: 0.01330437 \tValidation Loss 0.01606721 \tTraining Acuuarcy 30.649% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 157 \tTraining Loss: 0.01328956 \tValidation Loss 0.01601488 \tTraining Acuuarcy 31.050% \tValidation Acuuarcy 22.820%\n",
      "Epoch: 158 \tTraining Loss: 0.01330347 \tValidation Loss 0.01586294 \tTraining Acuuarcy 31.446% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 159 \tTraining Loss: 0.01327051 \tValidation Loss 0.01595865 \tTraining Acuuarcy 31.345% \tValidation Acuuarcy 22.903%\n",
      "Epoch: 160 \tTraining Loss: 0.01325407 \tValidation Loss 0.01600371 \tTraining Acuuarcy 31.401% \tValidation Acuuarcy 22.430%\n",
      "Epoch: 161 \tTraining Loss: 0.01331341 \tValidation Loss 0.01591888 \tTraining Acuuarcy 30.827% \tValidation Acuuarcy 21.733%\n",
      "Epoch: 162 \tTraining Loss: 0.01328206 \tValidation Loss 0.01584735 \tTraining Acuuarcy 31.490% \tValidation Acuuarcy 22.597%\n",
      "Epoch: 163 \tTraining Loss: 0.01326910 \tValidation Loss 0.01609301 \tTraining Acuuarcy 31.228% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 164 \tTraining Loss: 0.01324831 \tValidation Loss 0.01612544 \tTraining Acuuarcy 31.212% \tValidation Acuuarcy 21.789%\n",
      "Epoch: 165 \tTraining Loss: 0.01328763 \tValidation Loss 0.01588665 \tTraining Acuuarcy 31.078% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 166 \tTraining Loss: 0.01324850 \tValidation Loss 0.01632092 \tTraining Acuuarcy 30.866% \tValidation Acuuarcy 21.928%\n",
      "Epoch: 167 \tTraining Loss: 0.01332678 \tValidation Loss 0.01593170 \tTraining Acuuarcy 31.262% \tValidation Acuuarcy 23.488%\n",
      "Epoch: 168 \tTraining Loss: 0.01325522 \tValidation Loss 0.01582956 \tTraining Acuuarcy 31.290% \tValidation Acuuarcy 22.931%\n",
      "Epoch: 169 \tTraining Loss: 0.01326823 \tValidation Loss 0.01633176 \tTraining Acuuarcy 31.518% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 170 \tTraining Loss: 0.01331788 \tValidation Loss 0.01592841 \tTraining Acuuarcy 31.111% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 171 \tTraining Loss: 0.01331492 \tValidation Loss 0.01610778 \tTraining Acuuarcy 30.855% \tValidation Acuuarcy 21.733%\n",
      "Epoch: 172 \tTraining Loss: 0.01325896 \tValidation Loss 0.01603044 \tTraining Acuuarcy 31.384% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 173 \tTraining Loss: 0.01327006 \tValidation Loss 0.01630044 \tTraining Acuuarcy 31.362% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 174 \tTraining Loss: 0.01326966 \tValidation Loss 0.01592225 \tTraining Acuuarcy 31.156% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 175 \tTraining Loss: 0.01326069 \tValidation Loss 0.01603573 \tTraining Acuuarcy 31.139% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 176 \tTraining Loss: 0.01328216 \tValidation Loss 0.01595462 \tTraining Acuuarcy 30.777% \tValidation Acuuarcy 22.207%\n",
      "Epoch: 177 \tTraining Loss: 0.01326474 \tValidation Loss 0.01588029 \tTraining Acuuarcy 30.994% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 178 \tTraining Loss: 0.01320916 \tValidation Loss 0.01612061 \tTraining Acuuarcy 31.685% \tValidation Acuuarcy 23.015%\n",
      "Epoch: 179 \tTraining Loss: 0.01326204 \tValidation Loss 0.01598152 \tTraining Acuuarcy 31.022% \tValidation Acuuarcy 22.820%\n",
      "Epoch: 180 \tTraining Loss: 0.01321175 \tValidation Loss 0.01592534 \tTraining Acuuarcy 31.680% \tValidation Acuuarcy 21.845%\n",
      "Epoch: 181 \tTraining Loss: 0.01321049 \tValidation Loss 0.01592493 \tTraining Acuuarcy 31.295% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 182 \tTraining Loss: 0.01322204 \tValidation Loss 0.01607262 \tTraining Acuuarcy 31.217% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 183 \tTraining Loss: 0.01323856 \tValidation Loss 0.01595953 \tTraining Acuuarcy 31.646% \tValidation Acuuarcy 22.736%\n",
      "Epoch: 184 \tTraining Loss: 0.01325727 \tValidation Loss 0.01590904 \tTraining Acuuarcy 31.072% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 185 \tTraining Loss: 0.01318047 \tValidation Loss 0.01612551 \tTraining Acuuarcy 31.763% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 186 \tTraining Loss: 0.01322147 \tValidation Loss 0.01592611 \tTraining Acuuarcy 31.518% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 187 \tTraining Loss: 0.01324610 \tValidation Loss 0.01610717 \tTraining Acuuarcy 31.201% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 188 \tTraining Loss: 0.01321917 \tValidation Loss 0.01610553 \tTraining Acuuarcy 31.513% \tValidation Acuuarcy 22.458%\n",
      "Epoch: 189 \tTraining Loss: 0.01320454 \tValidation Loss 0.01604782 \tTraining Acuuarcy 31.630% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 190 \tTraining Loss: 0.01325556 \tValidation Loss 0.01583437 \tTraining Acuuarcy 30.732% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 191 \tTraining Loss: 0.01325228 \tValidation Loss 0.01595495 \tTraining Acuuarcy 31.100% \tValidation Acuuarcy 22.207%\n",
      "Epoch: 192 \tTraining Loss: 0.01321247 \tValidation Loss 0.01602942 \tTraining Acuuarcy 31.552% \tValidation Acuuarcy 22.012%\n",
      "Epoch: 193 \tTraining Loss: 0.01317398 \tValidation Loss 0.01584114 \tTraining Acuuarcy 31.702% \tValidation Acuuarcy 22.541%\n",
      "Epoch: 194 \tTraining Loss: 0.01319275 \tValidation Loss 0.01592740 \tTraining Acuuarcy 31.853% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 195 \tTraining Loss: 0.01319140 \tValidation Loss 0.01598041 \tTraining Acuuarcy 31.780% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 196 \tTraining Loss: 0.01319403 \tValidation Loss 0.01603383 \tTraining Acuuarcy 31.373% \tValidation Acuuarcy 22.318%\n",
      "Epoch: 197 \tTraining Loss: 0.01320294 \tValidation Loss 0.01592498 \tTraining Acuuarcy 31.502% \tValidation Acuuarcy 21.482%\n",
      "Epoch: 198 \tTraining Loss: 0.01316432 \tValidation Loss 0.01635060 \tTraining Acuuarcy 31.959% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 199 \tTraining Loss: 0.01316658 \tValidation Loss 0.01617662 \tTraining Acuuarcy 31.702% \tValidation Acuuarcy 21.705%\n",
      "Epoch: 200 \tTraining Loss: 0.01319675 \tValidation Loss 0.01603375 \tTraining Acuuarcy 31.318% \tValidation Acuuarcy 22.040%\n",
      "Epoch: 201 \tTraining Loss: 0.01317354 \tValidation Loss 0.01585608 \tTraining Acuuarcy 31.942% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 202 \tTraining Loss: 0.01318139 \tValidation Loss 0.01610045 \tTraining Acuuarcy 32.142% \tValidation Acuuarcy 21.817%\n",
      "Epoch: 203 \tTraining Loss: 0.01314461 \tValidation Loss 0.01608523 \tTraining Acuuarcy 32.059% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 204 \tTraining Loss: 0.01316254 \tValidation Loss 0.01621379 \tTraining Acuuarcy 31.535% \tValidation Acuuarcy 22.040%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 205 \tTraining Loss: 0.01315661 \tValidation Loss 0.01592531 \tTraining Acuuarcy 32.115% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 206 \tTraining Loss: 0.01317132 \tValidation Loss 0.01617150 \tTraining Acuuarcy 32.103% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 207 \tTraining Loss: 0.01314929 \tValidation Loss 0.01608420 \tTraining Acuuarcy 31.613% \tValidation Acuuarcy 22.179%\n",
      "Epoch: 208 \tTraining Loss: 0.01313058 \tValidation Loss 0.01601541 \tTraining Acuuarcy 32.382% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 209 \tTraining Loss: 0.01312028 \tValidation Loss 0.01614949 \tTraining Acuuarcy 32.081% \tValidation Acuuarcy 21.984%\n",
      "Epoch: 210 \tTraining Loss: 0.01311052 \tValidation Loss 0.01602693 \tTraining Acuuarcy 32.382% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 211 \tTraining Loss: 0.01313437 \tValidation Loss 0.01625360 \tTraining Acuuarcy 31.658% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 212 \tTraining Loss: 0.01312891 \tValidation Loss 0.01610502 \tTraining Acuuarcy 32.237% \tValidation Acuuarcy 22.848%\n",
      "Epoch: 213 \tTraining Loss: 0.01310320 \tValidation Loss 0.01592197 \tTraining Acuuarcy 32.148% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 214 \tTraining Loss: 0.01312231 \tValidation Loss 0.01611025 \tTraining Acuuarcy 32.477% \tValidation Acuuarcy 21.956%\n",
      "Epoch: 215 \tTraining Loss: 0.01314899 \tValidation Loss 0.01582796 \tTraining Acuuarcy 32.360% \tValidation Acuuarcy 22.541%\n",
      "Epoch: 216 \tTraining Loss: 0.01308714 \tValidation Loss 0.01626628 \tTraining Acuuarcy 32.438% \tValidation Acuuarcy 22.485%\n",
      "Epoch: 217 \tTraining Loss: 0.01312587 \tValidation Loss 0.01609095 \tTraining Acuuarcy 32.416% \tValidation Acuuarcy 21.900%\n",
      "Epoch: 218 \tTraining Loss: 0.01310753 \tValidation Loss 0.01606604 \tTraining Acuuarcy 32.204% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 219 \tTraining Loss: 0.01309110 \tValidation Loss 0.01606286 \tTraining Acuuarcy 32.248% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 220 \tTraining Loss: 0.01309552 \tValidation Loss 0.01612541 \tTraining Acuuarcy 32.187% \tValidation Acuuarcy 21.984%\n",
      "Epoch: 221 \tTraining Loss: 0.01319176 \tValidation Loss 0.01622091 \tTraining Acuuarcy 31.674% \tValidation Acuuarcy 21.984%\n",
      "Epoch: 222 \tTraining Loss: 0.01312655 \tValidation Loss 0.01622888 \tTraining Acuuarcy 32.315% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 223 \tTraining Loss: 0.01309031 \tValidation Loss 0.01643790 \tTraining Acuuarcy 32.109% \tValidation Acuuarcy 22.235%\n",
      "Epoch: 224 \tTraining Loss: 0.01308448 \tValidation Loss 0.01626740 \tTraining Acuuarcy 32.232% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 225 \tTraining Loss: 0.01312867 \tValidation Loss 0.01610124 \tTraining Acuuarcy 32.031% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 226 \tTraining Loss: 0.01312924 \tValidation Loss 0.01606800 \tTraining Acuuarcy 32.533% \tValidation Acuuarcy 22.151%\n",
      "Epoch: 227 \tTraining Loss: 0.01303919 \tValidation Loss 0.01619553 \tTraining Acuuarcy 32.599% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 228 \tTraining Loss: 0.01309746 \tValidation Loss 0.01635855 \tTraining Acuuarcy 32.878% \tValidation Acuuarcy 21.482%\n",
      "Epoch: 229 \tTraining Loss: 0.01309397 \tValidation Loss 0.01608710 \tTraining Acuuarcy 32.577% \tValidation Acuuarcy 22.290%\n",
      "Epoch: 230 \tTraining Loss: 0.01305250 \tValidation Loss 0.01602994 \tTraining Acuuarcy 32.226% \tValidation Acuuarcy 22.123%\n",
      "Epoch: 231 \tTraining Loss: 0.01306643 \tValidation Loss 0.01600878 \tTraining Acuuarcy 32.689% \tValidation Acuuarcy 21.649%\n",
      "Epoch: 232 \tTraining Loss: 0.01304790 \tValidation Loss 0.01610258 \tTraining Acuuarcy 32.399% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 233 \tTraining Loss: 0.01311446 \tValidation Loss 0.01606378 \tTraining Acuuarcy 32.750% \tValidation Acuuarcy 22.541%\n",
      "Epoch: 234 \tTraining Loss: 0.01310590 \tValidation Loss 0.01620391 \tTraining Acuuarcy 32.304% \tValidation Acuuarcy 22.485%\n",
      "Epoch: 235 \tTraining Loss: 0.01307515 \tValidation Loss 0.01624175 \tTraining Acuuarcy 32.599% \tValidation Acuuarcy 22.012%\n",
      "Epoch: 236 \tTraining Loss: 0.01305096 \tValidation Loss 0.01607610 \tTraining Acuuarcy 32.326% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 237 \tTraining Loss: 0.01305637 \tValidation Loss 0.01622429 \tTraining Acuuarcy 32.633% \tValidation Acuuarcy 22.458%\n",
      "Epoch: 238 \tTraining Loss: 0.01311069 \tValidation Loss 0.01619080 \tTraining Acuuarcy 32.020% \tValidation Acuuarcy 21.817%\n",
      "Epoch: 239 \tTraining Loss: 0.01303883 \tValidation Loss 0.01650339 \tTraining Acuuarcy 33.073% \tValidation Acuuarcy 21.287%\n",
      "Epoch: 240 \tTraining Loss: 0.01306764 \tValidation Loss 0.01616824 \tTraining Acuuarcy 32.850% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 241 \tTraining Loss: 0.01302874 \tValidation Loss 0.01605956 \tTraining Acuuarcy 32.923% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 242 \tTraining Loss: 0.01298182 \tValidation Loss 0.01626239 \tTraining Acuuarcy 32.834% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 243 \tTraining Loss: 0.01306751 \tValidation Loss 0.01622571 \tTraining Acuuarcy 32.471% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 244 \tTraining Loss: 0.01308762 \tValidation Loss 0.01623471 \tTraining Acuuarcy 32.722% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 245 \tTraining Loss: 0.01304103 \tValidation Loss 0.01595473 \tTraining Acuuarcy 32.945% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 246 \tTraining Loss: 0.01305621 \tValidation Loss 0.01592948 \tTraining Acuuarcy 32.806% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 247 \tTraining Loss: 0.01303601 \tValidation Loss 0.01632259 \tTraining Acuuarcy 32.867% \tValidation Acuuarcy 22.040%\n",
      "Epoch: 248 \tTraining Loss: 0.01307313 \tValidation Loss 0.01615394 \tTraining Acuuarcy 32.516% \tValidation Acuuarcy 22.541%\n",
      "Epoch: 249 \tTraining Loss: 0.01307117 \tValidation Loss 0.01585574 \tTraining Acuuarcy 32.678% \tValidation Acuuarcy 21.845%\n",
      "Epoch: 250 \tTraining Loss: 0.01300972 \tValidation Loss 0.01615426 \tTraining Acuuarcy 33.057% \tValidation Acuuarcy 22.290%\n",
      "Epoch: 251 \tTraining Loss: 0.01303112 \tValidation Loss 0.01609415 \tTraining Acuuarcy 32.655% \tValidation Acuuarcy 22.151%\n",
      "Epoch: 252 \tTraining Loss: 0.01299558 \tValidation Loss 0.01588475 \tTraining Acuuarcy 33.213% \tValidation Acuuarcy 22.123%\n",
      "Epoch: 253 \tTraining Loss: 0.01303942 \tValidation Loss 0.01625763 \tTraining Acuuarcy 32.973% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 254 \tTraining Loss: 0.01307395 \tValidation Loss 0.01595836 \tTraining Acuuarcy 32.817% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 255 \tTraining Loss: 0.01304191 \tValidation Loss 0.01609745 \tTraining Acuuarcy 32.834% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 256 \tTraining Loss: 0.01302335 \tValidation Loss 0.01642879 \tTraining Acuuarcy 33.352% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 257 \tTraining Loss: 0.01304675 \tValidation Loss 0.01625189 \tTraining Acuuarcy 32.633% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 258 \tTraining Loss: 0.01301868 \tValidation Loss 0.01639388 \tTraining Acuuarcy 32.822% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 259 \tTraining Loss: 0.01300611 \tValidation Loss 0.01639215 \tTraining Acuuarcy 32.906% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 260 \tTraining Loss: 0.01299324 \tValidation Loss 0.01607676 \tTraining Acuuarcy 32.973% \tValidation Acuuarcy 22.513%\n",
      "Epoch: 261 \tTraining Loss: 0.01301538 \tValidation Loss 0.01647801 \tTraining Acuuarcy 32.633% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 262 \tTraining Loss: 0.01301169 \tValidation Loss 0.01619281 \tTraining Acuuarcy 33.268% \tValidation Acuuarcy 21.817%\n",
      "Epoch: 263 \tTraining Loss: 0.01303255 \tValidation Loss 0.01632756 \tTraining Acuuarcy 32.828% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 264 \tTraining Loss: 0.01295146 \tValidation Loss 0.01668847 \tTraining Acuuarcy 33.268% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 265 \tTraining Loss: 0.01302316 \tValidation Loss 0.01605833 \tTraining Acuuarcy 33.224% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 266 \tTraining Loss: 0.01302314 \tValidation Loss 0.01598634 \tTraining Acuuarcy 33.034% \tValidation Acuuarcy 21.928%\n",
      "Epoch: 267 \tTraining Loss: 0.01305584 \tValidation Loss 0.01620949 \tTraining Acuuarcy 33.146% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 268 \tTraining Loss: 0.01295337 \tValidation Loss 0.01644499 \tTraining Acuuarcy 33.597% \tValidation Acuuarcy 21.900%\n",
      "Epoch: 269 \tTraining Loss: 0.01297847 \tValidation Loss 0.01617088 \tTraining Acuuarcy 33.235% \tValidation Acuuarcy 21.594%\n",
      "Epoch: 270 \tTraining Loss: 0.01303639 \tValidation Loss 0.01617026 \tTraining Acuuarcy 32.990% \tValidation Acuuarcy 21.900%\n",
      "Epoch: 271 \tTraining Loss: 0.01301314 \tValidation Loss 0.01610002 \tTraining Acuuarcy 33.040% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 272 \tTraining Loss: 0.01300750 \tValidation Loss 0.01627996 \tTraining Acuuarcy 33.463% \tValidation Acuuarcy 21.900%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273 \tTraining Loss: 0.01300275 \tValidation Loss 0.01627427 \tTraining Acuuarcy 32.789% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 274 \tTraining Loss: 0.01305043 \tValidation Loss 0.01628995 \tTraining Acuuarcy 32.611% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 275 \tTraining Loss: 0.01300225 \tValidation Loss 0.01653938 \tTraining Acuuarcy 32.678% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 276 \tTraining Loss: 0.01298307 \tValidation Loss 0.01607258 \tTraining Acuuarcy 33.692% \tValidation Acuuarcy 22.931%\n",
      "Epoch: 277 \tTraining Loss: 0.01298155 \tValidation Loss 0.01634708 \tTraining Acuuarcy 33.252% \tValidation Acuuarcy 21.705%\n",
      "Epoch: 278 \tTraining Loss: 0.01303085 \tValidation Loss 0.01603575 \tTraining Acuuarcy 33.029% \tValidation Acuuarcy 22.262%\n",
      "Epoch: 279 \tTraining Loss: 0.01295826 \tValidation Loss 0.01617406 \tTraining Acuuarcy 33.168% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 280 \tTraining Loss: 0.01298514 \tValidation Loss 0.01605584 \tTraining Acuuarcy 33.090% \tValidation Acuuarcy 22.262%\n",
      "Epoch: 281 \tTraining Loss: 0.01299772 \tValidation Loss 0.01656934 \tTraining Acuuarcy 32.806% \tValidation Acuuarcy 22.820%\n",
      "Epoch: 282 \tTraining Loss: 0.01303896 \tValidation Loss 0.01612273 \tTraining Acuuarcy 32.510% \tValidation Acuuarcy 21.789%\n",
      "Epoch: 283 \tTraining Loss: 0.01295934 \tValidation Loss 0.01626864 \tTraining Acuuarcy 33.335% \tValidation Acuuarcy 21.510%\n",
      "Epoch: 284 \tTraining Loss: 0.01294381 \tValidation Loss 0.01640425 \tTraining Acuuarcy 33.714% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 285 \tTraining Loss: 0.01306111 \tValidation Loss 0.01621616 \tTraining Acuuarcy 32.800% \tValidation Acuuarcy 22.625%\n",
      "Epoch: 286 \tTraining Loss: 0.01295953 \tValidation Loss 0.01628450 \tTraining Acuuarcy 33.224% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 287 \tTraining Loss: 0.01294990 \tValidation Loss 0.01626755 \tTraining Acuuarcy 33.285% \tValidation Acuuarcy 21.482%\n",
      "Epoch: 288 \tTraining Loss: 0.01300099 \tValidation Loss 0.01605307 \tTraining Acuuarcy 33.530% \tValidation Acuuarcy 22.095%\n",
      "Epoch: 289 \tTraining Loss: 0.01301177 \tValidation Loss 0.01618193 \tTraining Acuuarcy 33.586% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 290 \tTraining Loss: 0.01298532 \tValidation Loss 0.01621662 \tTraining Acuuarcy 33.040% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 291 \tTraining Loss: 0.01298627 \tValidation Loss 0.01646184 \tTraining Acuuarcy 33.001% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 292 \tTraining Loss: 0.01301153 \tValidation Loss 0.01618437 \tTraining Acuuarcy 33.313% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 293 \tTraining Loss: 0.01295365 \tValidation Loss 0.01631987 \tTraining Acuuarcy 33.213% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 294 \tTraining Loss: 0.01298714 \tValidation Loss 0.01626758 \tTraining Acuuarcy 32.756% \tValidation Acuuarcy 21.872%\n",
      "Epoch: 295 \tTraining Loss: 0.01301819 \tValidation Loss 0.01627289 \tTraining Acuuarcy 32.906% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 296 \tTraining Loss: 0.01295467 \tValidation Loss 0.01628753 \tTraining Acuuarcy 33.792% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 297 \tTraining Loss: 0.01294959 \tValidation Loss 0.01642348 \tTraining Acuuarcy 33.151% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 298 \tTraining Loss: 0.01291452 \tValidation Loss 0.01633669 \tTraining Acuuarcy 33.497% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 299 \tTraining Loss: 0.01296654 \tValidation Loss 0.01609172 \tTraining Acuuarcy 33.252% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 300 \tTraining Loss: 0.01295126 \tValidation Loss 0.01638546 \tTraining Acuuarcy 33.162% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 301 \tTraining Loss: 0.01296194 \tValidation Loss 0.01651780 \tTraining Acuuarcy 33.101% \tValidation Acuuarcy 22.207%\n",
      "Epoch: 302 \tTraining Loss: 0.01295547 \tValidation Loss 0.01606733 \tTraining Acuuarcy 33.653% \tValidation Acuuarcy 22.708%\n",
      "Epoch: 303 \tTraining Loss: 0.01288246 \tValidation Loss 0.01645452 \tTraining Acuuarcy 34.004% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 304 \tTraining Loss: 0.01296856 \tValidation Loss 0.01635069 \tTraining Acuuarcy 32.945% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 305 \tTraining Loss: 0.01295571 \tValidation Loss 0.01603441 \tTraining Acuuarcy 33.291% \tValidation Acuuarcy 22.012%\n",
      "Epoch: 306 \tTraining Loss: 0.01301314 \tValidation Loss 0.01618411 \tTraining Acuuarcy 32.967% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 307 \tTraining Loss: 0.01291900 \tValidation Loss 0.01639186 \tTraining Acuuarcy 33.341% \tValidation Acuuarcy 22.262%\n",
      "Epoch: 308 \tTraining Loss: 0.01292773 \tValidation Loss 0.01625624 \tTraining Acuuarcy 33.285% \tValidation Acuuarcy 21.956%\n",
      "Epoch: 309 \tTraining Loss: 0.01293714 \tValidation Loss 0.01615374 \tTraining Acuuarcy 33.307% \tValidation Acuuarcy 21.984%\n",
      "Epoch: 310 \tTraining Loss: 0.01292288 \tValidation Loss 0.01683067 \tTraining Acuuarcy 33.536% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 311 \tTraining Loss: 0.01292306 \tValidation Loss 0.01642702 \tTraining Acuuarcy 33.909% \tValidation Acuuarcy 21.510%\n",
      "Epoch: 312 \tTraining Loss: 0.01292693 \tValidation Loss 0.01641065 \tTraining Acuuarcy 33.564% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 313 \tTraining Loss: 0.01292116 \tValidation Loss 0.01649233 \tTraining Acuuarcy 33.541% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 314 \tTraining Loss: 0.01296963 \tValidation Loss 0.01642996 \tTraining Acuuarcy 33.541% \tValidation Acuuarcy 21.845%\n",
      "Epoch: 315 \tTraining Loss: 0.01291423 \tValidation Loss 0.01668654 \tTraining Acuuarcy 33.140% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 316 \tTraining Loss: 0.01293719 \tValidation Loss 0.01639268 \tTraining Acuuarcy 33.815% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 317 \tTraining Loss: 0.01287158 \tValidation Loss 0.01638975 \tTraining Acuuarcy 33.803% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 318 \tTraining Loss: 0.01294219 \tValidation Loss 0.01649148 \tTraining Acuuarcy 33.764% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 319 \tTraining Loss: 0.01289189 \tValidation Loss 0.01685094 \tTraining Acuuarcy 33.658% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 320 \tTraining Loss: 0.01295256 \tValidation Loss 0.01621174 \tTraining Acuuarcy 33.982% \tValidation Acuuarcy 21.733%\n",
      "Epoch: 321 \tTraining Loss: 0.01294587 \tValidation Loss 0.01626216 \tTraining Acuuarcy 33.168% \tValidation Acuuarcy 22.095%\n",
      "Epoch: 322 \tTraining Loss: 0.01291686 \tValidation Loss 0.01624575 \tTraining Acuuarcy 33.185% \tValidation Acuuarcy 21.845%\n",
      "Epoch: 323 \tTraining Loss: 0.01291094 \tValidation Loss 0.01688820 \tTraining Acuuarcy 33.374% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 324 \tTraining Loss: 0.01296325 \tValidation Loss 0.01669947 \tTraining Acuuarcy 33.653% \tValidation Acuuarcy 22.458%\n",
      "Epoch: 325 \tTraining Loss: 0.01288264 \tValidation Loss 0.01682085 \tTraining Acuuarcy 33.959% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 326 \tTraining Loss: 0.01293279 \tValidation Loss 0.01665980 \tTraining Acuuarcy 33.803% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 327 \tTraining Loss: 0.01287365 \tValidation Loss 0.01625645 \tTraining Acuuarcy 33.692% \tValidation Acuuarcy 22.067%\n",
      "Epoch: 328 \tTraining Loss: 0.01290827 \tValidation Loss 0.01627712 \tTraining Acuuarcy 33.458% \tValidation Acuuarcy 22.374%\n",
      "Epoch: 329 \tTraining Loss: 0.01292811 \tValidation Loss 0.01631470 \tTraining Acuuarcy 33.720% \tValidation Acuuarcy 22.012%\n",
      "Epoch: 330 \tTraining Loss: 0.01292209 \tValidation Loss 0.01633636 \tTraining Acuuarcy 33.341% \tValidation Acuuarcy 22.095%\n",
      "Epoch: 331 \tTraining Loss: 0.01288394 \tValidation Loss 0.01662961 \tTraining Acuuarcy 33.887% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 332 \tTraining Loss: 0.01292677 \tValidation Loss 0.01635692 \tTraining Acuuarcy 33.937% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 333 \tTraining Loss: 0.01291799 \tValidation Loss 0.01609557 \tTraining Acuuarcy 33.603% \tValidation Acuuarcy 22.569%\n",
      "Epoch: 334 \tTraining Loss: 0.01287061 \tValidation Loss 0.01633377 \tTraining Acuuarcy 34.115% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 335 \tTraining Loss: 0.01285660 \tValidation Loss 0.01713402 \tTraining Acuuarcy 34.182% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 336 \tTraining Loss: 0.01286560 \tValidation Loss 0.01677637 \tTraining Acuuarcy 33.647% \tValidation Acuuarcy 20.006%\n",
      "Epoch: 337 \tTraining Loss: 0.01287473 \tValidation Loss 0.01692992 \tTraining Acuuarcy 33.998% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 338 \tTraining Loss: 0.01290760 \tValidation Loss 0.01641885 \tTraining Acuuarcy 34.082% \tValidation Acuuarcy 21.928%\n",
      "Epoch: 339 \tTraining Loss: 0.01291723 \tValidation Loss 0.01669325 \tTraining Acuuarcy 33.564% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 340 \tTraining Loss: 0.01286401 \tValidation Loss 0.01632805 \tTraining Acuuarcy 33.943% \tValidation Acuuarcy 22.235%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 341 \tTraining Loss: 0.01285493 \tValidation Loss 0.01682144 \tTraining Acuuarcy 33.920% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 342 \tTraining Loss: 0.01287696 \tValidation Loss 0.01630670 \tTraining Acuuarcy 34.082% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 343 \tTraining Loss: 0.01285071 \tValidation Loss 0.01695889 \tTraining Acuuarcy 34.333% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 344 \tTraining Loss: 0.01287096 \tValidation Loss 0.01662887 \tTraining Acuuarcy 34.026% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 345 \tTraining Loss: 0.01289594 \tValidation Loss 0.01628107 \tTraining Acuuarcy 33.887% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 346 \tTraining Loss: 0.01281893 \tValidation Loss 0.01634760 \tTraining Acuuarcy 34.021% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 347 \tTraining Loss: 0.01293807 \tValidation Loss 0.01645627 \tTraining Acuuarcy 33.809% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 348 \tTraining Loss: 0.01289750 \tValidation Loss 0.01649212 \tTraining Acuuarcy 33.436% \tValidation Acuuarcy 22.597%\n",
      "Epoch: 349 \tTraining Loss: 0.01291315 \tValidation Loss 0.01639506 \tTraining Acuuarcy 33.502% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 350 \tTraining Loss: 0.01286925 \tValidation Loss 0.01630162 \tTraining Acuuarcy 33.636% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 351 \tTraining Loss: 0.01294356 \tValidation Loss 0.01635671 \tTraining Acuuarcy 33.926% \tValidation Acuuarcy 22.235%\n",
      "Epoch: 352 \tTraining Loss: 0.01286068 \tValidation Loss 0.01687031 \tTraining Acuuarcy 33.692% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 353 \tTraining Loss: 0.01284984 \tValidation Loss 0.01643820 \tTraining Acuuarcy 34.255% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 354 \tTraining Loss: 0.01284926 \tValidation Loss 0.01663924 \tTraining Acuuarcy 34.422% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 355 \tTraining Loss: 0.01292749 \tValidation Loss 0.01639429 \tTraining Acuuarcy 33.603% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 356 \tTraining Loss: 0.01286329 \tValidation Loss 0.01649615 \tTraining Acuuarcy 34.054% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 357 \tTraining Loss: 0.01290511 \tValidation Loss 0.01644610 \tTraining Acuuarcy 34.216% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 358 \tTraining Loss: 0.01283834 \tValidation Loss 0.01639747 \tTraining Acuuarcy 34.511% \tValidation Acuuarcy 21.900%\n",
      "Epoch: 359 \tTraining Loss: 0.01282200 \tValidation Loss 0.01673960 \tTraining Acuuarcy 34.333% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 360 \tTraining Loss: 0.01286587 \tValidation Loss 0.01661508 \tTraining Acuuarcy 34.322% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 361 \tTraining Loss: 0.01290205 \tValidation Loss 0.01650801 \tTraining Acuuarcy 34.561% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 362 \tTraining Loss: 0.01283575 \tValidation Loss 0.01656458 \tTraining Acuuarcy 34.004% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 363 \tTraining Loss: 0.01287109 \tValidation Loss 0.01642804 \tTraining Acuuarcy 33.954% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 364 \tTraining Loss: 0.01280244 \tValidation Loss 0.01666514 \tTraining Acuuarcy 34.561% \tValidation Acuuarcy 22.485%\n",
      "Epoch: 365 \tTraining Loss: 0.01282676 \tValidation Loss 0.01644191 \tTraining Acuuarcy 33.954% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 366 \tTraining Loss: 0.01288535 \tValidation Loss 0.01642502 \tTraining Acuuarcy 33.569% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 367 \tTraining Loss: 0.01289508 \tValidation Loss 0.01628978 \tTraining Acuuarcy 34.104% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 368 \tTraining Loss: 0.01285306 \tValidation Loss 0.01640408 \tTraining Acuuarcy 34.115% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 369 \tTraining Loss: 0.01280983 \tValidation Loss 0.01673429 \tTraining Acuuarcy 34.288% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 370 \tTraining Loss: 0.01285187 \tValidation Loss 0.01651629 \tTraining Acuuarcy 33.965% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 371 \tTraining Loss: 0.01285826 \tValidation Loss 0.01628541 \tTraining Acuuarcy 34.311% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 372 \tTraining Loss: 0.01290578 \tValidation Loss 0.01617063 \tTraining Acuuarcy 33.553% \tValidation Acuuarcy 22.346%\n",
      "Epoch: 373 \tTraining Loss: 0.01284330 \tValidation Loss 0.01651759 \tTraining Acuuarcy 34.272% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 374 \tTraining Loss: 0.01289447 \tValidation Loss 0.01646300 \tTraining Acuuarcy 33.547% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 375 \tTraining Loss: 0.01283284 \tValidation Loss 0.01626287 \tTraining Acuuarcy 34.082% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 376 \tTraining Loss: 0.01284821 \tValidation Loss 0.01637773 \tTraining Acuuarcy 34.182% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 377 \tTraining Loss: 0.01289796 \tValidation Loss 0.01647034 \tTraining Acuuarcy 33.848% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 378 \tTraining Loss: 0.01285690 \tValidation Loss 0.01639854 \tTraining Acuuarcy 33.837% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 379 \tTraining Loss: 0.01280943 \tValidation Loss 0.01692379 \tTraining Acuuarcy 34.127% \tValidation Acuuarcy 19.811%\n",
      "Epoch: 380 \tTraining Loss: 0.01288857 \tValidation Loss 0.01652570 \tTraining Acuuarcy 33.993% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 381 \tTraining Loss: 0.01281599 \tValidation Loss 0.01643746 \tTraining Acuuarcy 34.416% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 382 \tTraining Loss: 0.01287417 \tValidation Loss 0.01646218 \tTraining Acuuarcy 33.725% \tValidation Acuuarcy 22.207%\n",
      "Epoch: 383 \tTraining Loss: 0.01285390 \tValidation Loss 0.01660666 \tTraining Acuuarcy 34.154% \tValidation Acuuarcy 20.061%\n",
      "Epoch: 384 \tTraining Loss: 0.01282046 \tValidation Loss 0.01652927 \tTraining Acuuarcy 34.338% \tValidation Acuuarcy 19.615%\n",
      "Epoch: 385 \tTraining Loss: 0.01278638 \tValidation Loss 0.01655980 \tTraining Acuuarcy 34.550% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 386 \tTraining Loss: 0.01284952 \tValidation Loss 0.01673289 \tTraining Acuuarcy 33.787% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 387 \tTraining Loss: 0.01282205 \tValidation Loss 0.01664771 \tTraining Acuuarcy 33.759% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 388 \tTraining Loss: 0.01282797 \tValidation Loss 0.01654525 \tTraining Acuuarcy 34.355% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 389 \tTraining Loss: 0.01281613 \tValidation Loss 0.01660771 \tTraining Acuuarcy 34.344% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 390 \tTraining Loss: 0.01283164 \tValidation Loss 0.01662740 \tTraining Acuuarcy 34.311% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 391 \tTraining Loss: 0.01285248 \tValidation Loss 0.01626314 \tTraining Acuuarcy 34.026% \tValidation Acuuarcy 21.817%\n",
      "Epoch: 392 \tTraining Loss: 0.01288171 \tValidation Loss 0.01648715 \tTraining Acuuarcy 33.976% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 393 \tTraining Loss: 0.01278420 \tValidation Loss 0.01664166 \tTraining Acuuarcy 34.517% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 394 \tTraining Loss: 0.01283176 \tValidation Loss 0.01645468 \tTraining Acuuarcy 34.355% \tValidation Acuuarcy 22.402%\n",
      "Epoch: 395 \tTraining Loss: 0.01283393 \tValidation Loss 0.01649834 \tTraining Acuuarcy 34.249% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 396 \tTraining Loss: 0.01286850 \tValidation Loss 0.01677910 \tTraining Acuuarcy 34.115% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 397 \tTraining Loss: 0.01284868 \tValidation Loss 0.01684492 \tTraining Acuuarcy 33.876% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 398 \tTraining Loss: 0.01283087 \tValidation Loss 0.01637714 \tTraining Acuuarcy 34.166% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 399 \tTraining Loss: 0.01282713 \tValidation Loss 0.01636381 \tTraining Acuuarcy 33.870% \tValidation Acuuarcy 18.891%\n",
      "Epoch: 400 \tTraining Loss: 0.01279939 \tValidation Loss 0.01666222 \tTraining Acuuarcy 34.595% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 401 \tTraining Loss: 0.01288918 \tValidation Loss 0.01660215 \tTraining Acuuarcy 33.759% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 402 \tTraining Loss: 0.01282228 \tValidation Loss 0.01628665 \tTraining Acuuarcy 34.199% \tValidation Acuuarcy 22.458%\n",
      "Epoch: 403 \tTraining Loss: 0.01284135 \tValidation Loss 0.01648683 \tTraining Acuuarcy 34.472% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 404 \tTraining Loss: 0.01285942 \tValidation Loss 0.01651709 \tTraining Acuuarcy 33.982% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 405 \tTraining Loss: 0.01280087 \tValidation Loss 0.01620172 \tTraining Acuuarcy 34.857% \tValidation Acuuarcy 22.095%\n",
      "Epoch: 406 \tTraining Loss: 0.01281583 \tValidation Loss 0.01636879 \tTraining Acuuarcy 34.506% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 407 \tTraining Loss: 0.01282421 \tValidation Loss 0.01639077 \tTraining Acuuarcy 34.272% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 408 \tTraining Loss: 0.01273867 \tValidation Loss 0.01650010 \tTraining Acuuarcy 34.478% \tValidation Acuuarcy 20.368%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 409 \tTraining Loss: 0.01280083 \tValidation Loss 0.01645250 \tTraining Acuuarcy 34.639% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 410 \tTraining Loss: 0.01279052 \tValidation Loss 0.01679925 \tTraining Acuuarcy 34.701% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 411 \tTraining Loss: 0.01279883 \tValidation Loss 0.01657694 \tTraining Acuuarcy 34.383% \tValidation Acuuarcy 21.482%\n",
      "Epoch: 412 \tTraining Loss: 0.01281262 \tValidation Loss 0.01640161 \tTraining Acuuarcy 34.556% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 413 \tTraining Loss: 0.01279465 \tValidation Loss 0.01622513 \tTraining Acuuarcy 34.667% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 414 \tTraining Loss: 0.01278672 \tValidation Loss 0.01669376 \tTraining Acuuarcy 34.272% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 415 \tTraining Loss: 0.01282744 \tValidation Loss 0.01662130 \tTraining Acuuarcy 34.021% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 416 \tTraining Loss: 0.01279050 \tValidation Loss 0.01652672 \tTraining Acuuarcy 34.823% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 417 \tTraining Loss: 0.01287176 \tValidation Loss 0.01653894 \tTraining Acuuarcy 34.004% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 418 \tTraining Loss: 0.01275638 \tValidation Loss 0.01657844 \tTraining Acuuarcy 34.651% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 419 \tTraining Loss: 0.01278139 \tValidation Loss 0.01667703 \tTraining Acuuarcy 34.868% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 420 \tTraining Loss: 0.01282529 \tValidation Loss 0.01676408 \tTraining Acuuarcy 34.506% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 421 \tTraining Loss: 0.01281584 \tValidation Loss 0.01672716 \tTraining Acuuarcy 34.483% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 422 \tTraining Loss: 0.01279885 \tValidation Loss 0.01685824 \tTraining Acuuarcy 34.539% \tValidation Acuuarcy 21.287%\n",
      "Epoch: 423 \tTraining Loss: 0.01281911 \tValidation Loss 0.01649557 \tTraining Acuuarcy 34.807% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 424 \tTraining Loss: 0.01276034 \tValidation Loss 0.01652968 \tTraining Acuuarcy 34.333% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 425 \tTraining Loss: 0.01279126 \tValidation Loss 0.01662231 \tTraining Acuuarcy 34.717% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 426 \tTraining Loss: 0.01282466 \tValidation Loss 0.01672058 \tTraining Acuuarcy 34.712% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 427 \tTraining Loss: 0.01277935 \tValidation Loss 0.01665155 \tTraining Acuuarcy 34.701% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 428 \tTraining Loss: 0.01277445 \tValidation Loss 0.01696545 \tTraining Acuuarcy 34.957% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 429 \tTraining Loss: 0.01278979 \tValidation Loss 0.01686294 \tTraining Acuuarcy 34.517% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 430 \tTraining Loss: 0.01285587 \tValidation Loss 0.01628648 \tTraining Acuuarcy 33.815% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 431 \tTraining Loss: 0.01279761 \tValidation Loss 0.01657910 \tTraining Acuuarcy 34.751% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 432 \tTraining Loss: 0.01278451 \tValidation Loss 0.01633511 \tTraining Acuuarcy 34.394% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 433 \tTraining Loss: 0.01282482 \tValidation Loss 0.01659682 \tTraining Acuuarcy 34.829% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 434 \tTraining Loss: 0.01278361 \tValidation Loss 0.01664679 \tTraining Acuuarcy 34.963% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 435 \tTraining Loss: 0.01278457 \tValidation Loss 0.01670245 \tTraining Acuuarcy 34.846% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 436 \tTraining Loss: 0.01273816 \tValidation Loss 0.01644122 \tTraining Acuuarcy 35.258% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 437 \tTraining Loss: 0.01277637 \tValidation Loss 0.01650942 \tTraining Acuuarcy 34.651% \tValidation Acuuarcy 19.783%\n",
      "Epoch: 438 \tTraining Loss: 0.01276626 \tValidation Loss 0.01678150 \tTraining Acuuarcy 34.812% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 439 \tTraining Loss: 0.01280278 \tValidation Loss 0.01678550 \tTraining Acuuarcy 34.489% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 440 \tTraining Loss: 0.01279368 \tValidation Loss 0.01702673 \tTraining Acuuarcy 34.812% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 441 \tTraining Loss: 0.01274294 \tValidation Loss 0.01664110 \tTraining Acuuarcy 35.035% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 442 \tTraining Loss: 0.01274426 \tValidation Loss 0.01662700 \tTraining Acuuarcy 34.901% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 443 \tTraining Loss: 0.01283300 \tValidation Loss 0.01640689 \tTraining Acuuarcy 34.227% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 444 \tTraining Loss: 0.01275819 \tValidation Loss 0.01713918 \tTraining Acuuarcy 34.907% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 445 \tTraining Loss: 0.01280403 \tValidation Loss 0.01671163 \tTraining Acuuarcy 34.795% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 446 \tTraining Loss: 0.01281718 \tValidation Loss 0.01691265 \tTraining Acuuarcy 34.316% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 447 \tTraining Loss: 0.01282958 \tValidation Loss 0.01672733 \tTraining Acuuarcy 34.918% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 448 \tTraining Loss: 0.01278701 \tValidation Loss 0.01658852 \tTraining Acuuarcy 34.511% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 449 \tTraining Loss: 0.01275238 \tValidation Loss 0.01631072 \tTraining Acuuarcy 35.024% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 450 \tTraining Loss: 0.01274001 \tValidation Loss 0.01669226 \tTraining Acuuarcy 35.186% \tValidation Acuuarcy 21.649%\n",
      "Epoch: 451 \tTraining Loss: 0.01277165 \tValidation Loss 0.01674908 \tTraining Acuuarcy 34.756% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 452 \tTraining Loss: 0.01277214 \tValidation Loss 0.01650851 \tTraining Acuuarcy 34.717% \tValidation Acuuarcy 21.594%\n",
      "Epoch: 453 \tTraining Loss: 0.01281752 \tValidation Loss 0.01648565 \tTraining Acuuarcy 34.283% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 454 \tTraining Loss: 0.01277459 \tValidation Loss 0.01686295 \tTraining Acuuarcy 34.929% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 455 \tTraining Loss: 0.01281571 \tValidation Loss 0.01670780 \tTraining Acuuarcy 34.149% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 456 \tTraining Loss: 0.01276372 \tValidation Loss 0.01658494 \tTraining Acuuarcy 34.851% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 457 \tTraining Loss: 0.01283542 \tValidation Loss 0.01649626 \tTraining Acuuarcy 34.394% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 458 \tTraining Loss: 0.01276645 \tValidation Loss 0.01702828 \tTraining Acuuarcy 34.745% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 459 \tTraining Loss: 0.01278311 \tValidation Loss 0.01666339 \tTraining Acuuarcy 34.935% \tValidation Acuuarcy 21.705%\n",
      "Epoch: 460 \tTraining Loss: 0.01271691 \tValidation Loss 0.01649496 \tTraining Acuuarcy 35.241% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 461 \tTraining Loss: 0.01276867 \tValidation Loss 0.01648772 \tTraining Acuuarcy 34.846% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 462 \tTraining Loss: 0.01274121 \tValidation Loss 0.01664054 \tTraining Acuuarcy 34.963% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 463 \tTraining Loss: 0.01280673 \tValidation Loss 0.01675716 \tTraining Acuuarcy 34.645% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 464 \tTraining Loss: 0.01278390 \tValidation Loss 0.01651459 \tTraining Acuuarcy 35.035% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 465 \tTraining Loss: 0.01280408 \tValidation Loss 0.01661640 \tTraining Acuuarcy 34.494% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 466 \tTraining Loss: 0.01274327 \tValidation Loss 0.01649651 \tTraining Acuuarcy 34.968% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 467 \tTraining Loss: 0.01274927 \tValidation Loss 0.01667359 \tTraining Acuuarcy 34.489% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 468 \tTraining Loss: 0.01278380 \tValidation Loss 0.01659546 \tTraining Acuuarcy 34.573% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 469 \tTraining Loss: 0.01274558 \tValidation Loss 0.01636007 \tTraining Acuuarcy 34.901% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 470 \tTraining Loss: 0.01275700 \tValidation Loss 0.01689441 \tTraining Acuuarcy 35.258% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 471 \tTraining Loss: 0.01273725 \tValidation Loss 0.01663617 \tTraining Acuuarcy 34.734% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 472 \tTraining Loss: 0.01274967 \tValidation Loss 0.01634816 \tTraining Acuuarcy 34.991% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 473 \tTraining Loss: 0.01270447 \tValidation Loss 0.01685815 \tTraining Acuuarcy 34.873% \tValidation Acuuarcy 19.420%\n",
      "Epoch: 474 \tTraining Loss: 0.01272835 \tValidation Loss 0.01683442 \tTraining Acuuarcy 35.280% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 475 \tTraining Loss: 0.01272173 \tValidation Loss 0.01652916 \tTraining Acuuarcy 35.347% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 476 \tTraining Loss: 0.01270109 \tValidation Loss 0.01684294 \tTraining Acuuarcy 35.297% \tValidation Acuuarcy 21.009%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 477 \tTraining Loss: 0.01269909 \tValidation Loss 0.01659043 \tTraining Acuuarcy 35.013% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 478 \tTraining Loss: 0.01276608 \tValidation Loss 0.01673696 \tTraining Acuuarcy 34.606% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 479 \tTraining Loss: 0.01269359 \tValidation Loss 0.01646139 \tTraining Acuuarcy 35.197% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 480 \tTraining Loss: 0.01275988 \tValidation Loss 0.01672749 \tTraining Acuuarcy 34.957% \tValidation Acuuarcy 21.761%\n",
      "Epoch: 481 \tTraining Loss: 0.01278105 \tValidation Loss 0.01662416 \tTraining Acuuarcy 35.063% \tValidation Acuuarcy 19.671%\n",
      "Epoch: 482 \tTraining Loss: 0.01272216 \tValidation Loss 0.01663063 \tTraining Acuuarcy 35.046% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 483 \tTraining Loss: 0.01272227 \tValidation Loss 0.01622763 \tTraining Acuuarcy 34.940% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 484 \tTraining Loss: 0.01273349 \tValidation Loss 0.01692304 \tTraining Acuuarcy 35.135% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 485 \tTraining Loss: 0.01274582 \tValidation Loss 0.01622500 \tTraining Acuuarcy 34.968% \tValidation Acuuarcy 21.482%\n",
      "Epoch: 486 \tTraining Loss: 0.01274253 \tValidation Loss 0.01656261 \tTraining Acuuarcy 35.230% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 487 \tTraining Loss: 0.01268403 \tValidation Loss 0.01673341 \tTraining Acuuarcy 35.141% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 488 \tTraining Loss: 0.01269379 \tValidation Loss 0.01717667 \tTraining Acuuarcy 35.258% \tValidation Acuuarcy 19.058%\n",
      "Epoch: 489 \tTraining Loss: 0.01273013 \tValidation Loss 0.01632624 \tTraining Acuuarcy 34.885% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 490 \tTraining Loss: 0.01278169 \tValidation Loss 0.01661880 \tTraining Acuuarcy 34.500% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 491 \tTraining Loss: 0.01274033 \tValidation Loss 0.01663385 \tTraining Acuuarcy 35.325% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 492 \tTraining Loss: 0.01273419 \tValidation Loss 0.01689963 \tTraining Acuuarcy 34.996% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 493 \tTraining Loss: 0.01273586 \tValidation Loss 0.01672267 \tTraining Acuuarcy 34.795% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 494 \tTraining Loss: 0.01271752 \tValidation Loss 0.01692003 \tTraining Acuuarcy 35.197% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 495 \tTraining Loss: 0.01276350 \tValidation Loss 0.01689570 \tTraining Acuuarcy 34.762% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 496 \tTraining Loss: 0.01276699 \tValidation Loss 0.01679901 \tTraining Acuuarcy 35.186% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 497 \tTraining Loss: 0.01272183 \tValidation Loss 0.01669555 \tTraining Acuuarcy 34.901% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 498 \tTraining Loss: 0.01269988 \tValidation Loss 0.01656562 \tTraining Acuuarcy 35.347% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 499 \tTraining Loss: 0.01271587 \tValidation Loss 0.01690675 \tTraining Acuuarcy 34.912% \tValidation Acuuarcy 19.393%\n",
      "Epoch: 500 \tTraining Loss: 0.01277260 \tValidation Loss 0.01716741 \tTraining Acuuarcy 35.219% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 501 \tTraining Loss: 0.01272710 \tValidation Loss 0.01688891 \tTraining Acuuarcy 35.386% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 502 \tTraining Loss: 0.01274702 \tValidation Loss 0.01618585 \tTraining Acuuarcy 35.085% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 503 \tTraining Loss: 0.01263497 \tValidation Loss 0.01688363 \tTraining Acuuarcy 35.648% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 504 \tTraining Loss: 0.01274258 \tValidation Loss 0.01674173 \tTraining Acuuarcy 34.873% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 505 \tTraining Loss: 0.01268978 \tValidation Loss 0.01658410 \tTraining Acuuarcy 34.946% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 506 \tTraining Loss: 0.01271281 \tValidation Loss 0.01656070 \tTraining Acuuarcy 34.974% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 507 \tTraining Loss: 0.01274915 \tValidation Loss 0.01662635 \tTraining Acuuarcy 34.968% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 508 \tTraining Loss: 0.01271657 \tValidation Loss 0.01688477 \tTraining Acuuarcy 35.258% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 509 \tTraining Loss: 0.01269938 \tValidation Loss 0.01682113 \tTraining Acuuarcy 35.303% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 510 \tTraining Loss: 0.01266149 \tValidation Loss 0.01679406 \tTraining Acuuarcy 35.487% \tValidation Acuuarcy 19.476%\n",
      "Epoch: 511 \tTraining Loss: 0.01274309 \tValidation Loss 0.01692380 \tTraining Acuuarcy 34.996% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 512 \tTraining Loss: 0.01269985 \tValidation Loss 0.01682105 \tTraining Acuuarcy 35.386% \tValidation Acuuarcy 22.151%\n",
      "Epoch: 513 \tTraining Loss: 0.01268732 \tValidation Loss 0.01675977 \tTraining Acuuarcy 35.475% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 514 \tTraining Loss: 0.01275646 \tValidation Loss 0.01649163 \tTraining Acuuarcy 35.314% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 515 \tTraining Loss: 0.01278125 \tValidation Loss 0.01611448 \tTraining Acuuarcy 34.439% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 516 \tTraining Loss: 0.01270605 \tValidation Loss 0.01700777 \tTraining Acuuarcy 35.063% \tValidation Acuuarcy 19.058%\n",
      "Epoch: 517 \tTraining Loss: 0.01271490 \tValidation Loss 0.01652278 \tTraining Acuuarcy 35.570% \tValidation Acuuarcy 19.783%\n",
      "Epoch: 518 \tTraining Loss: 0.01271421 \tValidation Loss 0.01652991 \tTraining Acuuarcy 35.052% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 519 \tTraining Loss: 0.01267569 \tValidation Loss 0.01666509 \tTraining Acuuarcy 35.654% \tValidation Acuuarcy 22.123%\n",
      "Epoch: 520 \tTraining Loss: 0.01273444 \tValidation Loss 0.01693669 \tTraining Acuuarcy 35.163% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 521 \tTraining Loss: 0.01271113 \tValidation Loss 0.01638982 \tTraining Acuuarcy 35.448% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 522 \tTraining Loss: 0.01273978 \tValidation Loss 0.01647419 \tTraining Acuuarcy 35.052% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 523 \tTraining Loss: 0.01269237 \tValidation Loss 0.01664529 \tTraining Acuuarcy 35.392% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 524 \tTraining Loss: 0.01273239 \tValidation Loss 0.01681102 \tTraining Acuuarcy 35.141% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 525 \tTraining Loss: 0.01270246 \tValidation Loss 0.01660076 \tTraining Acuuarcy 34.929% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 526 \tTraining Loss: 0.01271710 \tValidation Loss 0.01711143 \tTraining Acuuarcy 34.968% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 527 \tTraining Loss: 0.01266461 \tValidation Loss 0.01677998 \tTraining Acuuarcy 35.202% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 528 \tTraining Loss: 0.01267236 \tValidation Loss 0.01693309 \tTraining Acuuarcy 35.670% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 529 \tTraining Loss: 0.01268117 \tValidation Loss 0.01669489 \tTraining Acuuarcy 35.531% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 530 \tTraining Loss: 0.01272183 \tValidation Loss 0.01652064 \tTraining Acuuarcy 34.957% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 531 \tTraining Loss: 0.01270248 \tValidation Loss 0.01688233 \tTraining Acuuarcy 34.963% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 532 \tTraining Loss: 0.01269968 \tValidation Loss 0.01644048 \tTraining Acuuarcy 35.592% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 533 \tTraining Loss: 0.01273828 \tValidation Loss 0.01681258 \tTraining Acuuarcy 34.952% \tValidation Acuuarcy 21.538%\n",
      "Epoch: 534 \tTraining Loss: 0.01264185 \tValidation Loss 0.01702657 \tTraining Acuuarcy 35.520% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 535 \tTraining Loss: 0.01274917 \tValidation Loss 0.01672041 \tTraining Acuuarcy 34.912% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 536 \tTraining Loss: 0.01272252 \tValidation Loss 0.01665617 \tTraining Acuuarcy 35.241% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 537 \tTraining Loss: 0.01268286 \tValidation Loss 0.01682995 \tTraining Acuuarcy 35.358% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 538 \tTraining Loss: 0.01272103 \tValidation Loss 0.01676716 \tTraining Acuuarcy 35.799% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 539 \tTraining Loss: 0.01272848 \tValidation Loss 0.01695531 \tTraining Acuuarcy 35.269% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 540 \tTraining Loss: 0.01269591 \tValidation Loss 0.01665225 \tTraining Acuuarcy 35.180% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 541 \tTraining Loss: 0.01269538 \tValidation Loss 0.01634082 \tTraining Acuuarcy 35.186% \tValidation Acuuarcy 21.594%\n",
      "Epoch: 542 \tTraining Loss: 0.01273205 \tValidation Loss 0.01696609 \tTraining Acuuarcy 34.834% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 543 \tTraining Loss: 0.01269822 \tValidation Loss 0.01684843 \tTraining Acuuarcy 35.074% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 544 \tTraining Loss: 0.01274281 \tValidation Loss 0.01685341 \tTraining Acuuarcy 34.857% \tValidation Acuuarcy 20.535%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 545 \tTraining Loss: 0.01263851 \tValidation Loss 0.01680761 \tTraining Acuuarcy 35.749% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 546 \tTraining Loss: 0.01275406 \tValidation Loss 0.01639817 \tTraining Acuuarcy 35.085% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 547 \tTraining Loss: 0.01267136 \tValidation Loss 0.01652228 \tTraining Acuuarcy 35.893% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 548 \tTraining Loss: 0.01266828 \tValidation Loss 0.01691122 \tTraining Acuuarcy 35.392% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 549 \tTraining Loss: 0.01272339 \tValidation Loss 0.01664201 \tTraining Acuuarcy 34.868% \tValidation Acuuarcy 19.894%\n",
      "Epoch: 550 \tTraining Loss: 0.01271415 \tValidation Loss 0.01695123 \tTraining Acuuarcy 35.230% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 551 \tTraining Loss: 0.01265242 \tValidation Loss 0.01699080 \tTraining Acuuarcy 35.620% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 552 \tTraining Loss: 0.01266429 \tValidation Loss 0.01715211 \tTraining Acuuarcy 35.537% \tValidation Acuuarcy 19.337%\n",
      "Epoch: 553 \tTraining Loss: 0.01272785 \tValidation Loss 0.01699723 \tTraining Acuuarcy 34.846% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 554 \tTraining Loss: 0.01263938 \tValidation Loss 0.01686019 \tTraining Acuuarcy 35.414% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 555 \tTraining Loss: 0.01270483 \tValidation Loss 0.01695892 \tTraining Acuuarcy 35.052% \tValidation Acuuarcy 21.733%\n",
      "Epoch: 556 \tTraining Loss: 0.01263703 \tValidation Loss 0.01681455 \tTraining Acuuarcy 35.871% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 557 \tTraining Loss: 0.01267064 \tValidation Loss 0.01694763 \tTraining Acuuarcy 35.637% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 558 \tTraining Loss: 0.01266834 \tValidation Loss 0.01630382 \tTraining Acuuarcy 35.174% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 559 \tTraining Loss: 0.01264771 \tValidation Loss 0.01688192 \tTraining Acuuarcy 35.386% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 560 \tTraining Loss: 0.01268898 \tValidation Loss 0.01678815 \tTraining Acuuarcy 35.654% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 561 \tTraining Loss: 0.01268645 \tValidation Loss 0.01688753 \tTraining Acuuarcy 35.871% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 562 \tTraining Loss: 0.01265639 \tValidation Loss 0.01694374 \tTraining Acuuarcy 35.364% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 563 \tTraining Loss: 0.01270748 \tValidation Loss 0.01658531 \tTraining Acuuarcy 35.085% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 564 \tTraining Loss: 0.01270429 \tValidation Loss 0.01684998 \tTraining Acuuarcy 35.319% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 565 \tTraining Loss: 0.01267791 \tValidation Loss 0.01668391 \tTraining Acuuarcy 35.397% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 566 \tTraining Loss: 0.01269820 \tValidation Loss 0.01660946 \tTraining Acuuarcy 34.812% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 567 \tTraining Loss: 0.01263016 \tValidation Loss 0.01684830 \tTraining Acuuarcy 35.475% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 568 \tTraining Loss: 0.01269219 \tValidation Loss 0.01658319 \tTraining Acuuarcy 35.347% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 569 \tTraining Loss: 0.01265619 \tValidation Loss 0.01694540 \tTraining Acuuarcy 35.336% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 570 \tTraining Loss: 0.01262235 \tValidation Loss 0.01668599 \tTraining Acuuarcy 35.414% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 571 \tTraining Loss: 0.01264336 \tValidation Loss 0.01665978 \tTraining Acuuarcy 35.665% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 572 \tTraining Loss: 0.01265940 \tValidation Loss 0.01666353 \tTraining Acuuarcy 35.319% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 573 \tTraining Loss: 0.01267595 \tValidation Loss 0.01710539 \tTraining Acuuarcy 35.174% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 574 \tTraining Loss: 0.01263701 \tValidation Loss 0.01669998 \tTraining Acuuarcy 35.475% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 575 \tTraining Loss: 0.01263312 \tValidation Loss 0.01684646 \tTraining Acuuarcy 35.631% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 576 \tTraining Loss: 0.01266038 \tValidation Loss 0.01685063 \tTraining Acuuarcy 35.609% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 577 \tTraining Loss: 0.01259717 \tValidation Loss 0.01679626 \tTraining Acuuarcy 35.804% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 578 \tTraining Loss: 0.01265657 \tValidation Loss 0.01681760 \tTraining Acuuarcy 35.609% \tValidation Acuuarcy 21.566%\n",
      "Epoch: 579 \tTraining Loss: 0.01265249 \tValidation Loss 0.01676025 \tTraining Acuuarcy 35.576% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 580 \tTraining Loss: 0.01268289 \tValidation Loss 0.01656098 \tTraining Acuuarcy 35.570% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 581 \tTraining Loss: 0.01269071 \tValidation Loss 0.01670019 \tTraining Acuuarcy 35.331% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 582 \tTraining Loss: 0.01267441 \tValidation Loss 0.01710667 \tTraining Acuuarcy 35.542% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 583 \tTraining Loss: 0.01272104 \tValidation Loss 0.01675792 \tTraining Acuuarcy 35.459% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 584 \tTraining Loss: 0.01262604 \tValidation Loss 0.01680988 \tTraining Acuuarcy 35.453% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 585 \tTraining Loss: 0.01267869 \tValidation Loss 0.01717936 \tTraining Acuuarcy 35.347% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 586 \tTraining Loss: 0.01264593 \tValidation Loss 0.01681793 \tTraining Acuuarcy 36.005% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 587 \tTraining Loss: 0.01263143 \tValidation Loss 0.01640129 \tTraining Acuuarcy 35.944% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 588 \tTraining Loss: 0.01264050 \tValidation Loss 0.01635423 \tTraining Acuuarcy 35.710% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 589 \tTraining Loss: 0.01265462 \tValidation Loss 0.01688112 \tTraining Acuuarcy 35.570% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 590 \tTraining Loss: 0.01265424 \tValidation Loss 0.01711600 \tTraining Acuuarcy 35.648% \tValidation Acuuarcy 19.476%\n",
      "Epoch: 591 \tTraining Loss: 0.01269260 \tValidation Loss 0.01649254 \tTraining Acuuarcy 35.197% \tValidation Acuuarcy 21.510%\n",
      "Epoch: 592 \tTraining Loss: 0.01260323 \tValidation Loss 0.01712153 \tTraining Acuuarcy 35.983% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 593 \tTraining Loss: 0.01263108 \tValidation Loss 0.01657623 \tTraining Acuuarcy 36.010% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 594 \tTraining Loss: 0.01256778 \tValidation Loss 0.01687685 \tTraining Acuuarcy 35.910% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 595 \tTraining Loss: 0.01267014 \tValidation Loss 0.01680110 \tTraining Acuuarcy 35.303% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 596 \tTraining Loss: 0.01267571 \tValidation Loss 0.01675019 \tTraining Acuuarcy 35.615% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 597 \tTraining Loss: 0.01266070 \tValidation Loss 0.01683890 \tTraining Acuuarcy 35.464% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 598 \tTraining Loss: 0.01272253 \tValidation Loss 0.01670084 \tTraining Acuuarcy 35.030% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 599 \tTraining Loss: 0.01256794 \tValidation Loss 0.01708707 \tTraining Acuuarcy 35.821% \tValidation Acuuarcy 19.588%\n",
      "Epoch: 600 \tTraining Loss: 0.01261437 \tValidation Loss 0.01691882 \tTraining Acuuarcy 36.122% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 601 \tTraining Loss: 0.01265073 \tValidation Loss 0.01660506 \tTraining Acuuarcy 35.598% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 602 \tTraining Loss: 0.01259019 \tValidation Loss 0.01674249 \tTraining Acuuarcy 35.682% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 603 \tTraining Loss: 0.01262159 \tValidation Loss 0.01695912 \tTraining Acuuarcy 35.715% \tValidation Acuuarcy 21.733%\n",
      "Epoch: 604 \tTraining Loss: 0.01267775 \tValidation Loss 0.01665716 \tTraining Acuuarcy 35.464% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 605 \tTraining Loss: 0.01263957 \tValidation Loss 0.01709310 \tTraining Acuuarcy 35.498% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 606 \tTraining Loss: 0.01263634 \tValidation Loss 0.01679699 \tTraining Acuuarcy 35.726% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 607 \tTraining Loss: 0.01263333 \tValidation Loss 0.01701026 \tTraining Acuuarcy 35.559% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 608 \tTraining Loss: 0.01262538 \tValidation Loss 0.01690371 \tTraining Acuuarcy 36.339% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 609 \tTraining Loss: 0.01258395 \tValidation Loss 0.01658324 \tTraining Acuuarcy 35.665% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 610 \tTraining Loss: 0.01264527 \tValidation Loss 0.01670089 \tTraining Acuuarcy 35.966% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 611 \tTraining Loss: 0.01263316 \tValidation Loss 0.01635711 \tTraining Acuuarcy 35.448% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 612 \tTraining Loss: 0.01266293 \tValidation Loss 0.01684075 \tTraining Acuuarcy 35.492% \tValidation Acuuarcy 20.479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 613 \tTraining Loss: 0.01259433 \tValidation Loss 0.01673920 \tTraining Acuuarcy 35.810% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 614 \tTraining Loss: 0.01270188 \tValidation Loss 0.01680752 \tTraining Acuuarcy 35.381% \tValidation Acuuarcy 19.476%\n",
      "Epoch: 615 \tTraining Loss: 0.01261132 \tValidation Loss 0.01670694 \tTraining Acuuarcy 35.615% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 616 \tTraining Loss: 0.01262998 \tValidation Loss 0.01660227 \tTraining Acuuarcy 36.077% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 617 \tTraining Loss: 0.01257987 \tValidation Loss 0.01676622 \tTraining Acuuarcy 35.537% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 618 \tTraining Loss: 0.01260796 \tValidation Loss 0.01702655 \tTraining Acuuarcy 35.782% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 619 \tTraining Loss: 0.01261336 \tValidation Loss 0.01688110 \tTraining Acuuarcy 35.726% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 620 \tTraining Loss: 0.01262856 \tValidation Loss 0.01643817 \tTraining Acuuarcy 35.782% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 621 \tTraining Loss: 0.01262225 \tValidation Loss 0.01734653 \tTraining Acuuarcy 35.687% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 622 \tTraining Loss: 0.01263300 \tValidation Loss 0.01675327 \tTraining Acuuarcy 35.464% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 623 \tTraining Loss: 0.01257969 \tValidation Loss 0.01687176 \tTraining Acuuarcy 35.938% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 624 \tTraining Loss: 0.01269218 \tValidation Loss 0.01745694 \tTraining Acuuarcy 35.849% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 625 \tTraining Loss: 0.01254831 \tValidation Loss 0.01716001 \tTraining Acuuarcy 36.378% \tValidation Acuuarcy 19.838%\n",
      "Epoch: 626 \tTraining Loss: 0.01260614 \tValidation Loss 0.01682702 \tTraining Acuuarcy 35.854% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 627 \tTraining Loss: 0.01260977 \tValidation Loss 0.01668362 \tTraining Acuuarcy 35.710% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 628 \tTraining Loss: 0.01260331 \tValidation Loss 0.01691693 \tTraining Acuuarcy 35.983% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 629 \tTraining Loss: 0.01260187 \tValidation Loss 0.01634532 \tTraining Acuuarcy 36.133% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 630 \tTraining Loss: 0.01263381 \tValidation Loss 0.01657290 \tTraining Acuuarcy 35.654% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 631 \tTraining Loss: 0.01260820 \tValidation Loss 0.01693865 \tTraining Acuuarcy 35.676% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 632 \tTraining Loss: 0.01263635 \tValidation Loss 0.01678543 \tTraining Acuuarcy 35.609% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 633 \tTraining Loss: 0.01258607 \tValidation Loss 0.01692834 \tTraining Acuuarcy 35.971% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 634 \tTraining Loss: 0.01262812 \tValidation Loss 0.01793087 \tTraining Acuuarcy 36.049% \tValidation Acuuarcy 19.783%\n",
      "Epoch: 635 \tTraining Loss: 0.01268267 \tValidation Loss 0.01638483 \tTraining Acuuarcy 35.615% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 636 \tTraining Loss: 0.01262905 \tValidation Loss 0.01706988 \tTraining Acuuarcy 35.587% \tValidation Acuuarcy 21.510%\n",
      "Epoch: 637 \tTraining Loss: 0.01264389 \tValidation Loss 0.01672665 \tTraining Acuuarcy 35.353% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 638 \tTraining Loss: 0.01258392 \tValidation Loss 0.01669048 \tTraining Acuuarcy 35.765% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 639 \tTraining Loss: 0.01258562 \tValidation Loss 0.01663150 \tTraining Acuuarcy 36.144% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 640 \tTraining Loss: 0.01259152 \tValidation Loss 0.01689178 \tTraining Acuuarcy 36.278% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 641 \tTraining Loss: 0.01257273 \tValidation Loss 0.01699124 \tTraining Acuuarcy 35.810% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 642 \tTraining Loss: 0.01263787 \tValidation Loss 0.01678637 \tTraining Acuuarcy 35.654% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 643 \tTraining Loss: 0.01260039 \tValidation Loss 0.01695194 \tTraining Acuuarcy 35.804% \tValidation Acuuarcy 21.232%\n",
      "Epoch: 644 \tTraining Loss: 0.01264675 \tValidation Loss 0.01665845 \tTraining Acuuarcy 35.966% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 645 \tTraining Loss: 0.01254754 \tValidation Loss 0.01686741 \tTraining Acuuarcy 36.306% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 646 \tTraining Loss: 0.01258994 \tValidation Loss 0.01677904 \tTraining Acuuarcy 35.793% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 647 \tTraining Loss: 0.01262949 \tValidation Loss 0.01661417 \tTraining Acuuarcy 35.704% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 648 \tTraining Loss: 0.01262670 \tValidation Loss 0.01711213 \tTraining Acuuarcy 35.626% \tValidation Acuuarcy 19.588%\n",
      "Epoch: 649 \tTraining Loss: 0.01264292 \tValidation Loss 0.01667574 \tTraining Acuuarcy 35.537% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 650 \tTraining Loss: 0.01264112 \tValidation Loss 0.01681297 \tTraining Acuuarcy 35.537% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 651 \tTraining Loss: 0.01256351 \tValidation Loss 0.01697303 \tTraining Acuuarcy 36.016% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 652 \tTraining Loss: 0.01263265 \tValidation Loss 0.01695133 \tTraining Acuuarcy 36.105% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 653 \tTraining Loss: 0.01266731 \tValidation Loss 0.01697196 \tTraining Acuuarcy 35.871% \tValidation Acuuarcy 19.643%\n",
      "Epoch: 654 \tTraining Loss: 0.01263073 \tValidation Loss 0.01697958 \tTraining Acuuarcy 35.704% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 655 \tTraining Loss: 0.01263692 \tValidation Loss 0.01696920 \tTraining Acuuarcy 35.492% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 656 \tTraining Loss: 0.01263050 \tValidation Loss 0.01646690 \tTraining Acuuarcy 35.899% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 657 \tTraining Loss: 0.01266212 \tValidation Loss 0.01652067 \tTraining Acuuarcy 35.347% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 658 \tTraining Loss: 0.01263198 \tValidation Loss 0.01721283 \tTraining Acuuarcy 35.693% \tValidation Acuuarcy 19.393%\n",
      "Epoch: 659 \tTraining Loss: 0.01259721 \tValidation Loss 0.01681434 \tTraining Acuuarcy 36.027% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 660 \tTraining Loss: 0.01261648 \tValidation Loss 0.01650341 \tTraining Acuuarcy 35.509% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 661 \tTraining Loss: 0.01256088 \tValidation Loss 0.01685307 \tTraining Acuuarcy 36.462% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 662 \tTraining Loss: 0.01264488 \tValidation Loss 0.01681356 \tTraining Acuuarcy 35.520% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 663 \tTraining Loss: 0.01261182 \tValidation Loss 0.01682974 \tTraining Acuuarcy 35.609% \tValidation Acuuarcy 22.123%\n",
      "Epoch: 664 \tTraining Loss: 0.01268865 \tValidation Loss 0.01677860 \tTraining Acuuarcy 35.046% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 665 \tTraining Loss: 0.01262363 \tValidation Loss 0.01677176 \tTraining Acuuarcy 35.732% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 666 \tTraining Loss: 0.01265506 \tValidation Loss 0.01679142 \tTraining Acuuarcy 35.609% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 667 \tTraining Loss: 0.01265704 \tValidation Loss 0.01678844 \tTraining Acuuarcy 35.364% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 668 \tTraining Loss: 0.01261078 \tValidation Loss 0.01686154 \tTraining Acuuarcy 35.877% \tValidation Acuuarcy 19.420%\n",
      "Epoch: 669 \tTraining Loss: 0.01263558 \tValidation Loss 0.01696012 \tTraining Acuuarcy 36.072% \tValidation Acuuarcy 21.287%\n",
      "Epoch: 670 \tTraining Loss: 0.01258186 \tValidation Loss 0.01677476 \tTraining Acuuarcy 36.022% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 671 \tTraining Loss: 0.01256612 \tValidation Loss 0.01655980 \tTraining Acuuarcy 35.927% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 672 \tTraining Loss: 0.01257737 \tValidation Loss 0.01661361 \tTraining Acuuarcy 36.278% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 673 \tTraining Loss: 0.01260759 \tValidation Loss 0.01670695 \tTraining Acuuarcy 35.804% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 674 \tTraining Loss: 0.01266074 \tValidation Loss 0.01677737 \tTraining Acuuarcy 35.966% \tValidation Acuuarcy 19.699%\n",
      "Epoch: 675 \tTraining Loss: 0.01257583 \tValidation Loss 0.01688002 \tTraining Acuuarcy 36.423% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 676 \tTraining Loss: 0.01257070 \tValidation Loss 0.01671778 \tTraining Acuuarcy 36.077% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 677 \tTraining Loss: 0.01262312 \tValidation Loss 0.01658834 \tTraining Acuuarcy 35.325% \tValidation Acuuarcy 21.789%\n",
      "Epoch: 678 \tTraining Loss: 0.01257287 \tValidation Loss 0.01683519 \tTraining Acuuarcy 36.289% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 679 \tTraining Loss: 0.01259972 \tValidation Loss 0.01686221 \tTraining Acuuarcy 35.431% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 680 \tTraining Loss: 0.01264479 \tValidation Loss 0.01708556 \tTraining Acuuarcy 35.559% \tValidation Acuuarcy 18.807%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 681 \tTraining Loss: 0.01254571 \tValidation Loss 0.01673717 \tTraining Acuuarcy 36.534% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 682 \tTraining Loss: 0.01259537 \tValidation Loss 0.01679861 \tTraining Acuuarcy 36.167% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 683 \tTraining Loss: 0.01256030 \tValidation Loss 0.01690686 \tTraining Acuuarcy 36.211% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 684 \tTraining Loss: 0.01254688 \tValidation Loss 0.01683897 \tTraining Acuuarcy 36.100% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 685 \tTraining Loss: 0.01257475 \tValidation Loss 0.01652175 \tTraining Acuuarcy 36.005% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 686 \tTraining Loss: 0.01253397 \tValidation Loss 0.01683745 \tTraining Acuuarcy 36.022% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 687 \tTraining Loss: 0.01263245 \tValidation Loss 0.01690668 \tTraining Acuuarcy 35.297% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 688 \tTraining Loss: 0.01261018 \tValidation Loss 0.01673137 \tTraining Acuuarcy 35.921% \tValidation Acuuarcy 21.956%\n",
      "Epoch: 689 \tTraining Loss: 0.01258644 \tValidation Loss 0.01685834 \tTraining Acuuarcy 36.010% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 690 \tTraining Loss: 0.01252640 \tValidation Loss 0.01673519 \tTraining Acuuarcy 36.640% \tValidation Acuuarcy 19.476%\n",
      "Epoch: 691 \tTraining Loss: 0.01250348 \tValidation Loss 0.01732224 \tTraining Acuuarcy 36.311% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 692 \tTraining Loss: 0.01254318 \tValidation Loss 0.01732007 \tTraining Acuuarcy 36.484% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 693 \tTraining Loss: 0.01260212 \tValidation Loss 0.01670714 \tTraining Acuuarcy 35.626% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 694 \tTraining Loss: 0.01264075 \tValidation Loss 0.01661984 \tTraining Acuuarcy 35.559% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 695 \tTraining Loss: 0.01264450 \tValidation Loss 0.01672372 \tTraining Acuuarcy 36.061% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 696 \tTraining Loss: 0.01251736 \tValidation Loss 0.01663431 \tTraining Acuuarcy 36.774% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 697 \tTraining Loss: 0.01261758 \tValidation Loss 0.01684677 \tTraining Acuuarcy 35.637% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 698 \tTraining Loss: 0.01258725 \tValidation Loss 0.01665638 \tTraining Acuuarcy 35.999% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 699 \tTraining Loss: 0.01257372 \tValidation Loss 0.01671106 \tTraining Acuuarcy 36.228% \tValidation Acuuarcy 21.817%\n",
      "Epoch: 700 \tTraining Loss: 0.01255617 \tValidation Loss 0.01681323 \tTraining Acuuarcy 36.412% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 701 \tTraining Loss: 0.01253953 \tValidation Loss 0.01698348 \tTraining Acuuarcy 36.456% \tValidation Acuuarcy 21.371%\n",
      "Epoch: 702 \tTraining Loss: 0.01256398 \tValidation Loss 0.01695977 \tTraining Acuuarcy 36.423% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 703 \tTraining Loss: 0.01255799 \tValidation Loss 0.01672415 \tTraining Acuuarcy 36.094% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 704 \tTraining Loss: 0.01254665 \tValidation Loss 0.01687307 \tTraining Acuuarcy 35.815% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 705 \tTraining Loss: 0.01256519 \tValidation Loss 0.01677066 \tTraining Acuuarcy 35.882% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 706 \tTraining Loss: 0.01256994 \tValidation Loss 0.01674408 \tTraining Acuuarcy 36.111% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 707 \tTraining Loss: 0.01255462 \tValidation Loss 0.01734149 \tTraining Acuuarcy 36.278% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 708 \tTraining Loss: 0.01256122 \tValidation Loss 0.01715671 \tTraining Acuuarcy 36.245% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 709 \tTraining Loss: 0.01262021 \tValidation Loss 0.01687806 \tTraining Acuuarcy 35.821% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 710 \tTraining Loss: 0.01254993 \tValidation Loss 0.01662253 \tTraining Acuuarcy 36.289% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 711 \tTraining Loss: 0.01257090 \tValidation Loss 0.01701325 \tTraining Acuuarcy 35.949% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 712 \tTraining Loss: 0.01259760 \tValidation Loss 0.01664146 \tTraining Acuuarcy 35.866% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 713 \tTraining Loss: 0.01257596 \tValidation Loss 0.01666271 \tTraining Acuuarcy 36.183% \tValidation Acuuarcy 21.649%\n",
      "Epoch: 714 \tTraining Loss: 0.01261432 \tValidation Loss 0.01655723 \tTraining Acuuarcy 35.715% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 715 \tTraining Loss: 0.01257869 \tValidation Loss 0.01669730 \tTraining Acuuarcy 35.882% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 716 \tTraining Loss: 0.01251470 \tValidation Loss 0.01683676 \tTraining Acuuarcy 36.194% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 717 \tTraining Loss: 0.01257016 \tValidation Loss 0.01663968 \tTraining Acuuarcy 35.971% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 718 \tTraining Loss: 0.01257146 \tValidation Loss 0.01688790 \tTraining Acuuarcy 36.172% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 719 \tTraining Loss: 0.01256963 \tValidation Loss 0.01678356 \tTraining Acuuarcy 36.272% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 720 \tTraining Loss: 0.01256950 \tValidation Loss 0.01669138 \tTraining Acuuarcy 35.860% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 721 \tTraining Loss: 0.01256998 \tValidation Loss 0.01689863 \tTraining Acuuarcy 36.022% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 722 \tTraining Loss: 0.01255673 \tValidation Loss 0.01705975 \tTraining Acuuarcy 36.072% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 723 \tTraining Loss: 0.01256719 \tValidation Loss 0.01657048 \tTraining Acuuarcy 35.871% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 724 \tTraining Loss: 0.01254914 \tValidation Loss 0.01656804 \tTraining Acuuarcy 36.401% \tValidation Acuuarcy 20.563%\n",
      "Epoch: 725 \tTraining Loss: 0.01253455 \tValidation Loss 0.01676133 \tTraining Acuuarcy 35.799% \tValidation Acuuarcy 21.649%\n",
      "Epoch: 726 \tTraining Loss: 0.01255365 \tValidation Loss 0.01688992 \tTraining Acuuarcy 36.233% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 727 \tTraining Loss: 0.01256895 \tValidation Loss 0.01683098 \tTraining Acuuarcy 36.222% \tValidation Acuuarcy 19.225%\n",
      "Epoch: 728 \tTraining Loss: 0.01252374 \tValidation Loss 0.01666531 \tTraining Acuuarcy 36.601% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 729 \tTraining Loss: 0.01256144 \tValidation Loss 0.01673019 \tTraining Acuuarcy 36.161% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 730 \tTraining Loss: 0.01256714 \tValidation Loss 0.01705287 \tTraining Acuuarcy 36.306% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 731 \tTraining Loss: 0.01255050 \tValidation Loss 0.01710932 \tTraining Acuuarcy 36.155% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 732 \tTraining Loss: 0.01257984 \tValidation Loss 0.01664185 \tTraining Acuuarcy 36.206% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 733 \tTraining Loss: 0.01246765 \tValidation Loss 0.01729562 \tTraining Acuuarcy 36.601% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 734 \tTraining Loss: 0.01253027 \tValidation Loss 0.01693093 \tTraining Acuuarcy 36.523% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 735 \tTraining Loss: 0.01256342 \tValidation Loss 0.01656295 \tTraining Acuuarcy 36.445% \tValidation Acuuarcy 21.343%\n",
      "Epoch: 736 \tTraining Loss: 0.01254494 \tValidation Loss 0.01705702 \tTraining Acuuarcy 36.010% \tValidation Acuuarcy 18.919%\n",
      "Epoch: 737 \tTraining Loss: 0.01253314 \tValidation Loss 0.01704685 \tTraining Acuuarcy 36.434% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 738 \tTraining Loss: 0.01251502 \tValidation Loss 0.01677738 \tTraining Acuuarcy 36.568% \tValidation Acuuarcy 19.838%\n",
      "Epoch: 739 \tTraining Loss: 0.01249233 \tValidation Loss 0.01683911 \tTraining Acuuarcy 36.813% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 740 \tTraining Loss: 0.01256066 \tValidation Loss 0.01673097 \tTraining Acuuarcy 36.217% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 741 \tTraining Loss: 0.01249476 \tValidation Loss 0.01697097 \tTraining Acuuarcy 36.150% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 742 \tTraining Loss: 0.01261303 \tValidation Loss 0.01710572 \tTraining Acuuarcy 35.648% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 743 \tTraining Loss: 0.01253935 \tValidation Loss 0.01681275 \tTraining Acuuarcy 36.172% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 744 \tTraining Loss: 0.01257296 \tValidation Loss 0.01669043 \tTraining Acuuarcy 36.428% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 745 \tTraining Loss: 0.01245937 \tValidation Loss 0.01684661 \tTraining Acuuarcy 36.702% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 746 \tTraining Loss: 0.01253856 \tValidation Loss 0.01684114 \tTraining Acuuarcy 36.490% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 747 \tTraining Loss: 0.01249517 \tValidation Loss 0.01690008 \tTraining Acuuarcy 36.389% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 748 \tTraining Loss: 0.01247750 \tValidation Loss 0.01684602 \tTraining Acuuarcy 36.869% \tValidation Acuuarcy 21.009%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 749 \tTraining Loss: 0.01252524 \tValidation Loss 0.01695701 \tTraining Acuuarcy 36.573% \tValidation Acuuarcy 20.535%\n",
      "Epoch: 750 \tTraining Loss: 0.01254471 \tValidation Loss 0.01658229 \tTraining Acuuarcy 36.378% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 751 \tTraining Loss: 0.01254773 \tValidation Loss 0.01674506 \tTraining Acuuarcy 36.295% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 752 \tTraining Loss: 0.01255548 \tValidation Loss 0.01652938 \tTraining Acuuarcy 36.735% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 753 \tTraining Loss: 0.01253798 \tValidation Loss 0.01764178 \tTraining Acuuarcy 36.211% \tValidation Acuuarcy 19.281%\n",
      "Epoch: 754 \tTraining Loss: 0.01250590 \tValidation Loss 0.01727570 \tTraining Acuuarcy 36.518% \tValidation Acuuarcy 19.894%\n",
      "Epoch: 755 \tTraining Loss: 0.01253059 \tValidation Loss 0.01663509 \tTraining Acuuarcy 36.010% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 756 \tTraining Loss: 0.01251761 \tValidation Loss 0.01698077 \tTraining Acuuarcy 36.356% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 757 \tTraining Loss: 0.01251925 \tValidation Loss 0.01696170 \tTraining Acuuarcy 36.345% \tValidation Acuuarcy 19.393%\n",
      "Epoch: 758 \tTraining Loss: 0.01252805 \tValidation Loss 0.01720782 \tTraining Acuuarcy 36.239% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 759 \tTraining Loss: 0.01248122 \tValidation Loss 0.01699655 \tTraining Acuuarcy 36.735% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 760 \tTraining Loss: 0.01254189 \tValidation Loss 0.01657849 \tTraining Acuuarcy 36.373% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 761 \tTraining Loss: 0.01255188 \tValidation Loss 0.01720583 \tTraining Acuuarcy 36.245% \tValidation Acuuarcy 19.448%\n",
      "Epoch: 762 \tTraining Loss: 0.01250341 \tValidation Loss 0.01663640 \tTraining Acuuarcy 36.495% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 763 \tTraining Loss: 0.01245966 \tValidation Loss 0.01677967 \tTraining Acuuarcy 36.941% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 764 \tTraining Loss: 0.01253795 \tValidation Loss 0.01702432 \tTraining Acuuarcy 36.557% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 765 \tTraining Loss: 0.01256508 \tValidation Loss 0.01701674 \tTraining Acuuarcy 36.261% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 766 \tTraining Loss: 0.01248893 \tValidation Loss 0.01708654 \tTraining Acuuarcy 37.097% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 767 \tTraining Loss: 0.01248861 \tValidation Loss 0.01680974 \tTraining Acuuarcy 36.629% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 768 \tTraining Loss: 0.01244938 \tValidation Loss 0.01712754 \tTraining Acuuarcy 36.902% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 769 \tTraining Loss: 0.01255770 \tValidation Loss 0.01671605 \tTraining Acuuarcy 36.473% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 770 \tTraining Loss: 0.01253889 \tValidation Loss 0.01699738 \tTraining Acuuarcy 36.267% \tValidation Acuuarcy 19.699%\n",
      "Epoch: 771 \tTraining Loss: 0.01251954 \tValidation Loss 0.01664574 \tTraining Acuuarcy 36.395% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 772 \tTraining Loss: 0.01250298 \tValidation Loss 0.01697330 \tTraining Acuuarcy 36.194% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 773 \tTraining Loss: 0.01248117 \tValidation Loss 0.01685141 \tTraining Acuuarcy 36.886% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 774 \tTraining Loss: 0.01248749 \tValidation Loss 0.01689092 \tTraining Acuuarcy 36.874% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 775 \tTraining Loss: 0.01252495 \tValidation Loss 0.01707907 \tTraining Acuuarcy 36.378% \tValidation Acuuarcy 19.615%\n",
      "Epoch: 776 \tTraining Loss: 0.01250169 \tValidation Loss 0.01686328 \tTraining Acuuarcy 36.272% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 777 \tTraining Loss: 0.01250429 \tValidation Loss 0.01671776 \tTraining Acuuarcy 36.607% \tValidation Acuuarcy 20.953%\n",
      "Epoch: 778 \tTraining Loss: 0.01246993 \tValidation Loss 0.01670120 \tTraining Acuuarcy 36.980% \tValidation Acuuarcy 19.532%\n",
      "Epoch: 779 \tTraining Loss: 0.01253835 \tValidation Loss 0.01688830 \tTraining Acuuarcy 36.612% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 780 \tTraining Loss: 0.01251448 \tValidation Loss 0.01691894 \tTraining Acuuarcy 36.501% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 781 \tTraining Loss: 0.01250091 \tValidation Loss 0.01712474 \tTraining Acuuarcy 36.880% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 782 \tTraining Loss: 0.01256113 \tValidation Loss 0.01728779 \tTraining Acuuarcy 36.401% \tValidation Acuuarcy 19.588%\n",
      "Epoch: 783 \tTraining Loss: 0.01251795 \tValidation Loss 0.01679921 \tTraining Acuuarcy 36.757% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 784 \tTraining Loss: 0.01260005 \tValidation Loss 0.01657838 \tTraining Acuuarcy 36.161% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 785 \tTraining Loss: 0.01248602 \tValidation Loss 0.01685015 \tTraining Acuuarcy 36.451% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 786 \tTraining Loss: 0.01246203 \tValidation Loss 0.01701482 \tTraining Acuuarcy 36.696% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 787 \tTraining Loss: 0.01254804 \tValidation Loss 0.01698300 \tTraining Acuuarcy 36.250% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 788 \tTraining Loss: 0.01256175 \tValidation Loss 0.01648726 \tTraining Acuuarcy 36.378% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 789 \tTraining Loss: 0.01256654 \tValidation Loss 0.01708676 \tTraining Acuuarcy 36.295% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 790 \tTraining Loss: 0.01252252 \tValidation Loss 0.01681946 \tTraining Acuuarcy 36.774% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 791 \tTraining Loss: 0.01256308 \tValidation Loss 0.01646483 \tTraining Acuuarcy 36.468% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 792 \tTraining Loss: 0.01247912 \tValidation Loss 0.01691806 \tTraining Acuuarcy 36.830% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 793 \tTraining Loss: 0.01252101 \tValidation Loss 0.01711128 \tTraining Acuuarcy 36.267% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 794 \tTraining Loss: 0.01253315 \tValidation Loss 0.01679557 \tTraining Acuuarcy 36.568% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 795 \tTraining Loss: 0.01249989 \tValidation Loss 0.01688115 \tTraining Acuuarcy 36.657% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 796 \tTraining Loss: 0.01248451 \tValidation Loss 0.01692747 \tTraining Acuuarcy 36.295% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 797 \tTraining Loss: 0.01253060 \tValidation Loss 0.01678620 \tTraining Acuuarcy 36.434% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 798 \tTraining Loss: 0.01253509 \tValidation Loss 0.01697190 \tTraining Acuuarcy 36.573% \tValidation Acuuarcy 19.504%\n",
      "Epoch: 799 \tTraining Loss: 0.01253313 \tValidation Loss 0.01723140 \tTraining Acuuarcy 36.267% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 800 \tTraining Loss: 0.01250809 \tValidation Loss 0.01716075 \tTraining Acuuarcy 36.468% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 801 \tTraining Loss: 0.01257000 \tValidation Loss 0.01659678 \tTraining Acuuarcy 36.150% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 802 \tTraining Loss: 0.01250346 \tValidation Loss 0.01725892 \tTraining Acuuarcy 36.729% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 803 \tTraining Loss: 0.01250882 \tValidation Loss 0.01717831 \tTraining Acuuarcy 36.490% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 804 \tTraining Loss: 0.01254011 \tValidation Loss 0.01721323 \tTraining Acuuarcy 36.256% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 805 \tTraining Loss: 0.01244240 \tValidation Loss 0.01707560 \tTraining Acuuarcy 36.612% \tValidation Acuuarcy 19.365%\n",
      "Epoch: 806 \tTraining Loss: 0.01249547 \tValidation Loss 0.01677606 \tTraining Acuuarcy 36.813% \tValidation Acuuarcy 19.337%\n",
      "Epoch: 807 \tTraining Loss: 0.01249977 \tValidation Loss 0.01656523 \tTraining Acuuarcy 36.412% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 808 \tTraining Loss: 0.01252433 \tValidation Loss 0.01688806 \tTraining Acuuarcy 36.696% \tValidation Acuuarcy 20.006%\n",
      "Epoch: 809 \tTraining Loss: 0.01245179 \tValidation Loss 0.01702408 \tTraining Acuuarcy 37.047% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 810 \tTraining Loss: 0.01247400 \tValidation Loss 0.01693761 \tTraining Acuuarcy 36.908% \tValidation Acuuarcy 21.176%\n",
      "Epoch: 811 \tTraining Loss: 0.01250715 \tValidation Loss 0.01700168 \tTraining Acuuarcy 36.479% \tValidation Acuuarcy 19.253%\n",
      "Epoch: 812 \tTraining Loss: 0.01256740 \tValidation Loss 0.01672025 \tTraining Acuuarcy 35.877% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 813 \tTraining Loss: 0.01255627 \tValidation Loss 0.01696855 \tTraining Acuuarcy 36.345% \tValidation Acuuarcy 20.061%\n",
      "Epoch: 814 \tTraining Loss: 0.01257089 \tValidation Loss 0.01665723 \tTraining Acuuarcy 36.284% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 815 \tTraining Loss: 0.01252307 \tValidation Loss 0.01668575 \tTraining Acuuarcy 36.824% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 816 \tTraining Loss: 0.01245618 \tValidation Loss 0.01755467 \tTraining Acuuarcy 37.164% \tValidation Acuuarcy 19.894%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 817 \tTraining Loss: 0.01255123 \tValidation Loss 0.01706043 \tTraining Acuuarcy 36.495% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 818 \tTraining Loss: 0.01251466 \tValidation Loss 0.01681011 \tTraining Acuuarcy 36.512% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 819 \tTraining Loss: 0.01246709 \tValidation Loss 0.01683516 \tTraining Acuuarcy 36.640% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 820 \tTraining Loss: 0.01249013 \tValidation Loss 0.01703548 \tTraining Acuuarcy 36.702% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 821 \tTraining Loss: 0.01241123 \tValidation Loss 0.01700136 \tTraining Acuuarcy 37.270% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 822 \tTraining Loss: 0.01246186 \tValidation Loss 0.01699093 \tTraining Acuuarcy 37.131% \tValidation Acuuarcy 20.006%\n",
      "Epoch: 823 \tTraining Loss: 0.01248167 \tValidation Loss 0.01674782 \tTraining Acuuarcy 36.579% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 824 \tTraining Loss: 0.01245354 \tValidation Loss 0.01682385 \tTraining Acuuarcy 36.718% \tValidation Acuuarcy 19.643%\n",
      "Epoch: 825 \tTraining Loss: 0.01240553 \tValidation Loss 0.01698680 \tTraining Acuuarcy 37.298% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 826 \tTraining Loss: 0.01249754 \tValidation Loss 0.01692028 \tTraining Acuuarcy 36.941% \tValidation Acuuarcy 21.009%\n",
      "Epoch: 827 \tTraining Loss: 0.01249181 \tValidation Loss 0.01701624 \tTraining Acuuarcy 36.323% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 828 \tTraining Loss: 0.01249603 \tValidation Loss 0.01685894 \tTraining Acuuarcy 36.702% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 829 \tTraining Loss: 0.01249119 \tValidation Loss 0.01675368 \tTraining Acuuarcy 36.596% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 830 \tTraining Loss: 0.01252691 \tValidation Loss 0.01670143 \tTraining Acuuarcy 36.796% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 831 \tTraining Loss: 0.01246228 \tValidation Loss 0.01699847 \tTraining Acuuarcy 36.991% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 832 \tTraining Loss: 0.01250214 \tValidation Loss 0.01694385 \tTraining Acuuarcy 36.345% \tValidation Acuuarcy 21.204%\n",
      "Epoch: 833 \tTraining Loss: 0.01243764 \tValidation Loss 0.01684007 \tTraining Acuuarcy 36.757% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 834 \tTraining Loss: 0.01248445 \tValidation Loss 0.01688878 \tTraining Acuuarcy 36.579% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 835 \tTraining Loss: 0.01243776 \tValidation Loss 0.01678568 \tTraining Acuuarcy 37.092% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 836 \tTraining Loss: 0.01247236 \tValidation Loss 0.01723626 \tTraining Acuuarcy 36.713% \tValidation Acuuarcy 19.894%\n",
      "Epoch: 837 \tTraining Loss: 0.01241344 \tValidation Loss 0.01714606 \tTraining Acuuarcy 37.019% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 838 \tTraining Loss: 0.01257937 \tValidation Loss 0.01658411 \tTraining Acuuarcy 36.389% \tValidation Acuuarcy 21.120%\n",
      "Epoch: 839 \tTraining Loss: 0.01245980 \tValidation Loss 0.01657110 \tTraining Acuuarcy 37.086% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 840 \tTraining Loss: 0.01252969 \tValidation Loss 0.01723781 \tTraining Acuuarcy 36.323% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 841 \tTraining Loss: 0.01245315 \tValidation Loss 0.01712914 \tTraining Acuuarcy 37.003% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 842 \tTraining Loss: 0.01250088 \tValidation Loss 0.01655445 \tTraining Acuuarcy 36.640% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 843 \tTraining Loss: 0.01251173 \tValidation Loss 0.01672825 \tTraining Acuuarcy 36.089% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 844 \tTraining Loss: 0.01256372 \tValidation Loss 0.01702495 \tTraining Acuuarcy 36.194% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 845 \tTraining Loss: 0.01248635 \tValidation Loss 0.01698328 \tTraining Acuuarcy 36.323% \tValidation Acuuarcy 19.198%\n",
      "Epoch: 846 \tTraining Loss: 0.01257870 \tValidation Loss 0.01698488 \tTraining Acuuarcy 36.417% \tValidation Acuuarcy 19.337%\n",
      "Epoch: 847 \tTraining Loss: 0.01242701 \tValidation Loss 0.01665059 \tTraining Acuuarcy 37.053% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 848 \tTraining Loss: 0.01252818 \tValidation Loss 0.01686318 \tTraining Acuuarcy 36.284% \tValidation Acuuarcy 20.479%\n",
      "Epoch: 849 \tTraining Loss: 0.01250768 \tValidation Loss 0.01703784 \tTraining Acuuarcy 36.930% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 850 \tTraining Loss: 0.01251214 \tValidation Loss 0.01689510 \tTraining Acuuarcy 36.440% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 851 \tTraining Loss: 0.01254791 \tValidation Loss 0.01689790 \tTraining Acuuarcy 36.284% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 852 \tTraining Loss: 0.01249268 \tValidation Loss 0.01703594 \tTraining Acuuarcy 36.540% \tValidation Acuuarcy 20.006%\n",
      "Epoch: 853 \tTraining Loss: 0.01248185 \tValidation Loss 0.01711060 \tTraining Acuuarcy 36.389% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 854 \tTraining Loss: 0.01242794 \tValidation Loss 0.01682309 \tTraining Acuuarcy 37.170% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 855 \tTraining Loss: 0.01250250 \tValidation Loss 0.01654788 \tTraining Acuuarcy 36.495% \tValidation Acuuarcy 19.420%\n",
      "Epoch: 856 \tTraining Loss: 0.01245976 \tValidation Loss 0.01744994 \tTraining Acuuarcy 36.930% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 857 \tTraining Loss: 0.01254511 \tValidation Loss 0.01637081 \tTraining Acuuarcy 36.367% \tValidation Acuuarcy 19.309%\n",
      "Epoch: 858 \tTraining Loss: 0.01248827 \tValidation Loss 0.01748685 \tTraining Acuuarcy 36.518% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 859 \tTraining Loss: 0.01245454 \tValidation Loss 0.01711502 \tTraining Acuuarcy 36.807% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 860 \tTraining Loss: 0.01247908 \tValidation Loss 0.01714109 \tTraining Acuuarcy 36.724% \tValidation Acuuarcy 18.947%\n",
      "Epoch: 861 \tTraining Loss: 0.01246153 \tValidation Loss 0.01709167 \tTraining Acuuarcy 36.791% \tValidation Acuuarcy 19.532%\n",
      "Epoch: 862 \tTraining Loss: 0.01247415 \tValidation Loss 0.01699949 \tTraining Acuuarcy 37.019% \tValidation Acuuarcy 19.142%\n",
      "Epoch: 863 \tTraining Loss: 0.01246826 \tValidation Loss 0.01694618 \tTraining Acuuarcy 36.328% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 864 \tTraining Loss: 0.01249301 \tValidation Loss 0.01704743 \tTraining Acuuarcy 36.936% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 865 \tTraining Loss: 0.01244082 \tValidation Loss 0.01679254 \tTraining Acuuarcy 37.276% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 866 \tTraining Loss: 0.01246547 \tValidation Loss 0.01712572 \tTraining Acuuarcy 36.490% \tValidation Acuuarcy 19.030%\n",
      "Epoch: 867 \tTraining Loss: 0.01246945 \tValidation Loss 0.01657397 \tTraining Acuuarcy 36.886% \tValidation Acuuarcy 21.594%\n",
      "Epoch: 868 \tTraining Loss: 0.01250242 \tValidation Loss 0.01694562 \tTraining Acuuarcy 36.473% \tValidation Acuuarcy 20.897%\n",
      "Epoch: 869 \tTraining Loss: 0.01247074 \tValidation Loss 0.01705918 \tTraining Acuuarcy 36.590% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 870 \tTraining Loss: 0.01238192 \tValidation Loss 0.01682104 \tTraining Acuuarcy 37.365% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 871 \tTraining Loss: 0.01248491 \tValidation Loss 0.01710286 \tTraining Acuuarcy 36.501% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 872 \tTraining Loss: 0.01247172 \tValidation Loss 0.01695341 \tTraining Acuuarcy 37.008% \tValidation Acuuarcy 19.420%\n",
      "Epoch: 873 \tTraining Loss: 0.01241104 \tValidation Loss 0.01690617 \tTraining Acuuarcy 37.097% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 874 \tTraining Loss: 0.01243662 \tValidation Loss 0.01712895 \tTraining Acuuarcy 37.047% \tValidation Acuuarcy 20.730%\n",
      "Epoch: 875 \tTraining Loss: 0.01246621 \tValidation Loss 0.01706885 \tTraining Acuuarcy 37.131% \tValidation Acuuarcy 19.337%\n",
      "Epoch: 876 \tTraining Loss: 0.01251542 \tValidation Loss 0.01678421 \tTraining Acuuarcy 37.030% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 877 \tTraining Loss: 0.01241660 \tValidation Loss 0.01734344 \tTraining Acuuarcy 37.192% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 878 \tTraining Loss: 0.01248966 \tValidation Loss 0.01678222 \tTraining Acuuarcy 36.807% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 879 \tTraining Loss: 0.01249542 \tValidation Loss 0.01689942 \tTraining Acuuarcy 37.019% \tValidation Acuuarcy 19.727%\n",
      "Epoch: 880 \tTraining Loss: 0.01245065 \tValidation Loss 0.01726388 \tTraining Acuuarcy 37.209% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 881 \tTraining Loss: 0.01243109 \tValidation Loss 0.01726410 \tTraining Acuuarcy 37.136% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 882 \tTraining Loss: 0.01244165 \tValidation Loss 0.01694291 \tTraining Acuuarcy 36.886% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 883 \tTraining Loss: 0.01246382 \tValidation Loss 0.01681553 \tTraining Acuuarcy 36.412% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 884 \tTraining Loss: 0.01246778 \tValidation Loss 0.01675315 \tTraining Acuuarcy 37.058% \tValidation Acuuarcy 20.869%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 885 \tTraining Loss: 0.01241267 \tValidation Loss 0.01693808 \tTraining Acuuarcy 37.409% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 886 \tTraining Loss: 0.01257534 \tValidation Loss 0.01674996 \tTraining Acuuarcy 36.311% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 887 \tTraining Loss: 0.01249529 \tValidation Loss 0.01714094 \tTraining Acuuarcy 36.947% \tValidation Acuuarcy 20.061%\n",
      "Epoch: 888 \tTraining Loss: 0.01241341 \tValidation Loss 0.01668558 \tTraining Acuuarcy 37.175% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 889 \tTraining Loss: 0.01249866 \tValidation Loss 0.01680106 \tTraining Acuuarcy 36.568% \tValidation Acuuarcy 21.315%\n",
      "Epoch: 890 \tTraining Loss: 0.01244086 \tValidation Loss 0.01726549 \tTraining Acuuarcy 36.997% \tValidation Acuuarcy 21.454%\n",
      "Epoch: 891 \tTraining Loss: 0.01240171 \tValidation Loss 0.01715447 \tTraining Acuuarcy 37.025% \tValidation Acuuarcy 19.281%\n",
      "Epoch: 892 \tTraining Loss: 0.01244123 \tValidation Loss 0.01680072 \tTraining Acuuarcy 37.170% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 893 \tTraining Loss: 0.01248812 \tValidation Loss 0.01706469 \tTraining Acuuarcy 36.774% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 894 \tTraining Loss: 0.01249577 \tValidation Loss 0.01685762 \tTraining Acuuarcy 36.741% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 895 \tTraining Loss: 0.01253147 \tValidation Loss 0.01669115 \tTraining Acuuarcy 36.579% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 896 \tTraining Loss: 0.01250641 \tValidation Loss 0.01720380 \tTraining Acuuarcy 36.573% \tValidation Acuuarcy 20.507%\n",
      "Epoch: 897 \tTraining Loss: 0.01250227 \tValidation Loss 0.01721571 \tTraining Acuuarcy 36.395% \tValidation Acuuarcy 19.393%\n",
      "Epoch: 898 \tTraining Loss: 0.01245826 \tValidation Loss 0.01738651 \tTraining Acuuarcy 36.713% \tValidation Acuuarcy 20.173%\n",
      "Epoch: 899 \tTraining Loss: 0.01242190 \tValidation Loss 0.01719949 \tTraining Acuuarcy 37.019% \tValidation Acuuarcy 19.783%\n",
      "Epoch: 900 \tTraining Loss: 0.01244190 \tValidation Loss 0.01724499 \tTraining Acuuarcy 37.064% \tValidation Acuuarcy 18.863%\n",
      "Epoch: 901 \tTraining Loss: 0.01247900 \tValidation Loss 0.01697269 \tTraining Acuuarcy 36.657% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 902 \tTraining Loss: 0.01251576 \tValidation Loss 0.01671179 \tTraining Acuuarcy 36.250% \tValidation Acuuarcy 20.869%\n",
      "Epoch: 903 \tTraining Loss: 0.01250662 \tValidation Loss 0.01654945 \tTraining Acuuarcy 36.479% \tValidation Acuuarcy 19.755%\n",
      "Epoch: 904 \tTraining Loss: 0.01249455 \tValidation Loss 0.01684607 \tTraining Acuuarcy 36.768% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 905 \tTraining Loss: 0.01248879 \tValidation Loss 0.01760829 \tTraining Acuuarcy 36.590% \tValidation Acuuarcy 19.309%\n",
      "Epoch: 906 \tTraining Loss: 0.01243934 \tValidation Loss 0.01689162 \tTraining Acuuarcy 36.807% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 907 \tTraining Loss: 0.01242164 \tValidation Loss 0.01693865 \tTraining Acuuarcy 37.248% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 908 \tTraining Loss: 0.01240885 \tValidation Loss 0.01717047 \tTraining Acuuarcy 37.638% \tValidation Acuuarcy 19.476%\n",
      "Epoch: 909 \tTraining Loss: 0.01239965 \tValidation Loss 0.01700825 \tTraining Acuuarcy 37.984% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 910 \tTraining Loss: 0.01246860 \tValidation Loss 0.01673998 \tTraining Acuuarcy 36.847% \tValidation Acuuarcy 21.148%\n",
      "Epoch: 911 \tTraining Loss: 0.01251464 \tValidation Loss 0.01712132 \tTraining Acuuarcy 36.323% \tValidation Acuuarcy 20.674%\n",
      "Epoch: 912 \tTraining Loss: 0.01247161 \tValidation Loss 0.01701458 \tTraining Acuuarcy 37.086% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 913 \tTraining Loss: 0.01251204 \tValidation Loss 0.01685432 \tTraining Acuuarcy 36.590% \tValidation Acuuarcy 19.198%\n",
      "Epoch: 914 \tTraining Loss: 0.01246283 \tValidation Loss 0.01670973 \tTraining Acuuarcy 37.281% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 915 \tTraining Loss: 0.01242010 \tValidation Loss 0.01709856 \tTraining Acuuarcy 37.354% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 916 \tTraining Loss: 0.01246609 \tValidation Loss 0.01669535 \tTraining Acuuarcy 36.919% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 917 \tTraining Loss: 0.01255005 \tValidation Loss 0.01701566 \tTraining Acuuarcy 36.245% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 918 \tTraining Loss: 0.01246526 \tValidation Loss 0.01691074 \tTraining Acuuarcy 36.150% \tValidation Acuuarcy 20.284%\n",
      "Epoch: 919 \tTraining Loss: 0.01248322 \tValidation Loss 0.01691524 \tTraining Acuuarcy 36.685% \tValidation Acuuarcy 18.724%\n",
      "Epoch: 920 \tTraining Loss: 0.01246494 \tValidation Loss 0.01706023 \tTraining Acuuarcy 36.724% \tValidation Acuuarcy 21.092%\n",
      "Epoch: 921 \tTraining Loss: 0.01248807 \tValidation Loss 0.01675084 \tTraining Acuuarcy 36.501% \tValidation Acuuarcy 19.615%\n",
      "Epoch: 922 \tTraining Loss: 0.01243228 \tValidation Loss 0.01684512 \tTraining Acuuarcy 36.874% \tValidation Acuuarcy 19.978%\n",
      "Epoch: 923 \tTraining Loss: 0.01245735 \tValidation Loss 0.01673135 \tTraining Acuuarcy 36.624% \tValidation Acuuarcy 19.755%\n",
      "Epoch: 924 \tTraining Loss: 0.01245690 \tValidation Loss 0.01700691 \tTraining Acuuarcy 36.835% \tValidation Acuuarcy 19.783%\n",
      "Epoch: 925 \tTraining Loss: 0.01240603 \tValidation Loss 0.01700118 \tTraining Acuuarcy 37.538% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 926 \tTraining Loss: 0.01243110 \tValidation Loss 0.01695266 \tTraining Acuuarcy 36.668% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 927 \tTraining Loss: 0.01238941 \tValidation Loss 0.01682610 \tTraining Acuuarcy 37.426% \tValidation Acuuarcy 21.259%\n",
      "Epoch: 928 \tTraining Loss: 0.01246123 \tValidation Loss 0.01715948 \tTraining Acuuarcy 37.019% \tValidation Acuuarcy 19.420%\n",
      "Epoch: 929 \tTraining Loss: 0.01240443 \tValidation Loss 0.01693087 \tTraining Acuuarcy 36.869% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 930 \tTraining Loss: 0.01241209 \tValidation Loss 0.01721098 \tTraining Acuuarcy 37.092% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 931 \tTraining Loss: 0.01247984 \tValidation Loss 0.01696149 \tTraining Acuuarcy 36.908% \tValidation Acuuarcy 20.396%\n",
      "Epoch: 932 \tTraining Loss: 0.01247212 \tValidation Loss 0.01691947 \tTraining Acuuarcy 36.780% \tValidation Acuuarcy 20.368%\n",
      "Epoch: 933 \tTraining Loss: 0.01242021 \tValidation Loss 0.01733529 \tTraining Acuuarcy 36.824% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 934 \tTraining Loss: 0.01243260 \tValidation Loss 0.01719255 \tTraining Acuuarcy 36.791% \tValidation Acuuarcy 20.925%\n",
      "Epoch: 935 \tTraining Loss: 0.01248531 \tValidation Loss 0.01708181 \tTraining Acuuarcy 36.518% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 936 \tTraining Loss: 0.01241875 \tValidation Loss 0.01727051 \tTraining Acuuarcy 36.796% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 937 \tTraining Loss: 0.01250569 \tValidation Loss 0.01682589 \tTraining Acuuarcy 35.916% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 938 \tTraining Loss: 0.01244534 \tValidation Loss 0.01671526 \tTraining Acuuarcy 36.841% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 939 \tTraining Loss: 0.01248185 \tValidation Loss 0.01670504 \tTraining Acuuarcy 36.696% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 940 \tTraining Loss: 0.01244049 \tValidation Loss 0.01736057 \tTraining Acuuarcy 37.097% \tValidation Acuuarcy 19.615%\n",
      "Epoch: 941 \tTraining Loss: 0.01240354 \tValidation Loss 0.01670090 \tTraining Acuuarcy 37.370% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 942 \tTraining Loss: 0.01251634 \tValidation Loss 0.01711029 \tTraining Acuuarcy 36.607% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 943 \tTraining Loss: 0.01241421 \tValidation Loss 0.01698882 \tTraining Acuuarcy 37.069% \tValidation Acuuarcy 20.758%\n",
      "Epoch: 944 \tTraining Loss: 0.01237375 \tValidation Loss 0.01690578 \tTraining Acuuarcy 37.114% \tValidation Acuuarcy 20.619%\n",
      "Epoch: 945 \tTraining Loss: 0.01242833 \tValidation Loss 0.01717382 \tTraining Acuuarcy 37.131% \tValidation Acuuarcy 20.033%\n",
      "Epoch: 946 \tTraining Loss: 0.01240653 \tValidation Loss 0.01687034 \tTraining Acuuarcy 36.913% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 947 \tTraining Loss: 0.01244940 \tValidation Loss 0.01708076 \tTraining Acuuarcy 37.175% \tValidation Acuuarcy 19.365%\n",
      "Epoch: 948 \tTraining Loss: 0.01247355 \tValidation Loss 0.01695738 \tTraining Acuuarcy 36.417% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 949 \tTraining Loss: 0.01248615 \tValidation Loss 0.01703071 \tTraining Acuuarcy 36.546% \tValidation Acuuarcy 20.702%\n",
      "Epoch: 950 \tTraining Loss: 0.01240554 \tValidation Loss 0.01686337 \tTraining Acuuarcy 37.292% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 951 \tTraining Loss: 0.01240899 \tValidation Loss 0.01699274 \tTraining Acuuarcy 37.276% \tValidation Acuuarcy 20.256%\n",
      "Epoch: 952 \tTraining Loss: 0.01247525 \tValidation Loss 0.01677664 \tTraining Acuuarcy 36.523% \tValidation Acuuarcy 19.755%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 953 \tTraining Loss: 0.01245762 \tValidation Loss 0.01704258 \tTraining Acuuarcy 37.181% \tValidation Acuuarcy 20.117%\n",
      "Epoch: 954 \tTraining Loss: 0.01242754 \tValidation Loss 0.01679665 \tTraining Acuuarcy 37.064% \tValidation Acuuarcy 19.838%\n",
      "Epoch: 955 \tTraining Loss: 0.01238795 \tValidation Loss 0.01690362 \tTraining Acuuarcy 37.053% \tValidation Acuuarcy 19.643%\n",
      "Epoch: 956 \tTraining Loss: 0.01233355 \tValidation Loss 0.01695938 \tTraining Acuuarcy 37.900% \tValidation Acuuarcy 20.841%\n",
      "Epoch: 957 \tTraining Loss: 0.01244135 \tValidation Loss 0.01643558 \tTraining Acuuarcy 37.705% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 958 \tTraining Loss: 0.01248744 \tValidation Loss 0.01649975 \tTraining Acuuarcy 36.702% \tValidation Acuuarcy 20.424%\n",
      "Epoch: 959 \tTraining Loss: 0.01242162 \tValidation Loss 0.01723339 \tTraining Acuuarcy 36.796% \tValidation Acuuarcy 21.677%\n",
      "Epoch: 960 \tTraining Loss: 0.01242646 \tValidation Loss 0.01686810 \tTraining Acuuarcy 36.991% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 961 \tTraining Loss: 0.01236235 \tValidation Loss 0.01718083 \tTraining Acuuarcy 37.053% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 962 \tTraining Loss: 0.01246106 \tValidation Loss 0.01697153 \tTraining Acuuarcy 36.763% \tValidation Acuuarcy 20.786%\n",
      "Epoch: 963 \tTraining Loss: 0.01244702 \tValidation Loss 0.01697491 \tTraining Acuuarcy 37.203% \tValidation Acuuarcy 20.340%\n",
      "Epoch: 964 \tTraining Loss: 0.01245054 \tValidation Loss 0.01737110 \tTraining Acuuarcy 36.830% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 965 \tTraining Loss: 0.01243239 \tValidation Loss 0.01682232 \tTraining Acuuarcy 36.941% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 966 \tTraining Loss: 0.01243068 \tValidation Loss 0.01709550 \tTraining Acuuarcy 36.997% \tValidation Acuuarcy 20.312%\n",
      "Epoch: 967 \tTraining Loss: 0.01243534 \tValidation Loss 0.01718927 \tTraining Acuuarcy 37.265% \tValidation Acuuarcy 18.891%\n",
      "Epoch: 968 \tTraining Loss: 0.01240451 \tValidation Loss 0.01659711 \tTraining Acuuarcy 37.616% \tValidation Acuuarcy 20.814%\n",
      "Epoch: 969 \tTraining Loss: 0.01236260 \tValidation Loss 0.01737388 \tTraining Acuuarcy 37.761% \tValidation Acuuarcy 19.588%\n",
      "Epoch: 970 \tTraining Loss: 0.01243869 \tValidation Loss 0.01677249 \tTraining Acuuarcy 36.523% \tValidation Acuuarcy 19.811%\n",
      "Epoch: 971 \tTraining Loss: 0.01251450 \tValidation Loss 0.01698941 \tTraining Acuuarcy 36.601% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 972 \tTraining Loss: 0.01247037 \tValidation Loss 0.01678692 \tTraining Acuuarcy 37.125% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 973 \tTraining Loss: 0.01242867 \tValidation Loss 0.01671347 \tTraining Acuuarcy 37.153% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 974 \tTraining Loss: 0.01246622 \tValidation Loss 0.01714367 \tTraining Acuuarcy 37.147% \tValidation Acuuarcy 21.427%\n",
      "Epoch: 975 \tTraining Loss: 0.01243544 \tValidation Loss 0.01693407 \tTraining Acuuarcy 37.159% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 976 \tTraining Loss: 0.01247805 \tValidation Loss 0.01685909 \tTraining Acuuarcy 36.746% \tValidation Acuuarcy 20.145%\n",
      "Epoch: 977 \tTraining Loss: 0.01242734 \tValidation Loss 0.01719697 \tTraining Acuuarcy 36.624% \tValidation Acuuarcy 19.170%\n",
      "Epoch: 978 \tTraining Loss: 0.01241305 \tValidation Loss 0.01711280 \tTraining Acuuarcy 37.092% \tValidation Acuuarcy 20.006%\n",
      "Epoch: 979 \tTraining Loss: 0.01242872 \tValidation Loss 0.01690936 \tTraining Acuuarcy 37.159% \tValidation Acuuarcy 19.866%\n",
      "Epoch: 980 \tTraining Loss: 0.01243930 \tValidation Loss 0.01681833 \tTraining Acuuarcy 37.153% \tValidation Acuuarcy 20.646%\n",
      "Epoch: 981 \tTraining Loss: 0.01241381 \tValidation Loss 0.01689687 \tTraining Acuuarcy 36.897% \tValidation Acuuarcy 19.950%\n",
      "Epoch: 982 \tTraining Loss: 0.01246487 \tValidation Loss 0.01701020 \tTraining Acuuarcy 36.596% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 983 \tTraining Loss: 0.01234837 \tValidation Loss 0.01731395 \tTraining Acuuarcy 37.543% \tValidation Acuuarcy 19.922%\n",
      "Epoch: 984 \tTraining Loss: 0.01245687 \tValidation Loss 0.01669977 \tTraining Acuuarcy 36.690% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 985 \tTraining Loss: 0.01242466 \tValidation Loss 0.01703765 \tTraining Acuuarcy 37.304% \tValidation Acuuarcy 20.981%\n",
      "Epoch: 986 \tTraining Loss: 0.01240507 \tValidation Loss 0.01683007 \tTraining Acuuarcy 37.081% \tValidation Acuuarcy 20.591%\n",
      "Epoch: 987 \tTraining Loss: 0.01240270 \tValidation Loss 0.01704380 \tTraining Acuuarcy 37.014% \tValidation Acuuarcy 19.560%\n",
      "Epoch: 988 \tTraining Loss: 0.01239429 \tValidation Loss 0.01702731 \tTraining Acuuarcy 37.331% \tValidation Acuuarcy 20.089%\n",
      "Epoch: 989 \tTraining Loss: 0.01236839 \tValidation Loss 0.01681035 \tTraining Acuuarcy 37.175% \tValidation Acuuarcy 19.671%\n",
      "Epoch: 990 \tTraining Loss: 0.01243536 \tValidation Loss 0.01691700 \tTraining Acuuarcy 37.147% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 991 \tTraining Loss: 0.01241026 \tValidation Loss 0.01708021 \tTraining Acuuarcy 36.958% \tValidation Acuuarcy 21.399%\n",
      "Epoch: 992 \tTraining Loss: 0.01236464 \tValidation Loss 0.01699319 \tTraining Acuuarcy 37.460% \tValidation Acuuarcy 19.086%\n",
      "Epoch: 993 \tTraining Loss: 0.01235028 \tValidation Loss 0.01725966 \tTraining Acuuarcy 37.967% \tValidation Acuuarcy 20.201%\n",
      "Epoch: 994 \tTraining Loss: 0.01239376 \tValidation Loss 0.01705698 \tTraining Acuuarcy 37.565% \tValidation Acuuarcy 19.003%\n",
      "Epoch: 995 \tTraining Loss: 0.01239162 \tValidation Loss 0.01747420 \tTraining Acuuarcy 37.460% \tValidation Acuuarcy 20.451%\n",
      "Epoch: 996 \tTraining Loss: 0.01239175 \tValidation Loss 0.01738367 \tTraining Acuuarcy 36.880% \tValidation Acuuarcy 18.780%\n",
      "Epoch: 997 \tTraining Loss: 0.01239715 \tValidation Loss 0.01710575 \tTraining Acuuarcy 37.521% \tValidation Acuuarcy 21.064%\n",
      "Epoch: 998 \tTraining Loss: 0.01237199 \tValidation Loss 0.01715169 \tTraining Acuuarcy 37.315% \tValidation Acuuarcy 21.037%\n",
      "Epoch: 999 \tTraining Loss: 0.01238949 \tValidation Loss 0.01699788 \tTraining Acuuarcy 37.326% \tValidation Acuuarcy 20.228%\n",
      "Epoch: 1000 \tTraining Loss: 0.01238419 \tValidation Loss 0.01692498 \tTraining Acuuarcy 37.465% \tValidation Acuuarcy 21.148%\n",
      "===================================Training Finished===================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loaders import Plain_Dataset, eval_data_dataloader\n",
    "from deep_emotion import Deep_Emotion\n",
    "from generate_data import Generate_data\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"CUDA is not available. Make sure you have a CUDA-enabled GPU.\")\n",
    "\n",
    "def Train(epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        train_acc = train_correct.double() / len(train_dataset)\n",
    "        validation_loss =  validation_loss / len(validation_dataset)\n",
    "        val_acc = val_correct.double() / len(validation_dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    print(\"===================================Training Finished===================================\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description=\"Configuration of setup and training process\")\n",
    "#     parser.add_argument('-s', '--setup', type=bool, help='setup the dataset for the first time')\n",
    "#     parser.add_argument('-d', '--data', type=str,required= True,\n",
    "#                                help='data folder that contains data files that downloaded from kaggle (train.csv and test.csv)')\n",
    "#     parser.add_argument('-hparams', '--hyperparams', type=bool,\n",
    "#                                help='True when changing the hyperparameters e.g (batch size, LR, num. of epochs)')\n",
    "#     parser.add_argument('-e', '--epochs', type= int, help= 'number of epochs')\n",
    "#     parser.add_argument('-lr', '--learning_rate', type= float, help= 'value of learning rate')\n",
    "#     parser.add_argument('-bs', '--batch_size', type= int, help= 'training/validation batch size')\n",
    "#     parser.add_argument('-t', '--train', type=bool, help='True when training')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     if args.setup :\n",
    "#         generate_dataset = Generate_data(args.data)\n",
    "#         generate_dataset.split_test()\n",
    "#         generate_dataset.save_images('train')\n",
    "#         generate_dataset.save_images('test')\n",
    "#         generate_dataset.save_images('val')\n",
    "\n",
    "#     if args.hyperparams:\n",
    "#         epochs = args.epochs\n",
    "#         lr = args.learning_rate\n",
    "#         batchsize = args.batch_size\n",
    "#     else :\n",
    "epochs = 1000\n",
    "lr = 0.005\n",
    "batchsize = 128\n",
    "\n",
    "#     if args.train:\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "print(\"Model archticture: \", net)\n",
    "traincsv_file = 'data'+'/'+'train.csv'\n",
    "validationcsv_file = 'data'+'/'+'val.csv'\n",
    "train_img_dir = 'data'+'/'+'train/'\n",
    "validation_img_dir = 'data'+'/'+'val/'\n",
    "\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n",
    "validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n",
    "train_loader= DataLoader(train_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "val_loader=   DataLoader(validation_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optmizer= optim.Adam(net.parameters(),lr= lr)\n",
    "Train(epochs, train_loader, val_loader, criterion, optmizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a48963",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'Speaktrum_by_SOVA_Final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ece8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deep_Emotion(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=810, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=7, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=640, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b35ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m roi_color \u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[0;32m     32\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m facess \u001b[38;5;241m=\u001b[39m \u001b[43mfaceCascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(facess) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace not detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry, take a deep breath\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust, look away for a second\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear, calm down\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy, you are good\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad, relax and meditate\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485ab460",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n\u001b[0;32m     50\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m(data)\n\u001b[0;32m     53\u001b[0m pred \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if (prediction == 0):\n",
    "                status = \"Angry, take a deep breath\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 1):\n",
    "                status = \"Disgust, look away for a second\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 2):\n",
    "                status = \"Fear, calm down\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 3):\n",
    "                status = \"Happy, you are good\"\n",
    "                color = (0, 0, 255)\n",
    "            elif (prediction == 4):\n",
    "                status = \"Sad, relax and meditate\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                status = \"\"\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "            x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "            cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, status, (x1 + int(w1 / 10), y1 + int(h1 / 2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(frame, status, (100, 150), font, 3, color, 2, cv2.LINE_4)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                    status,\n",
    "                    (50, 50),\n",
    "                    font, 0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_4)\n",
    "        cv2.imshow('Face', frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0240c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Deep_Emotion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net\u001b[38;5;241m=\u001b[39m \u001b[43mDeep_Emotion\u001b[49m()\n\u001b[0;32m      2\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Deep_Emotion' is not defined"
     ]
    }
   ],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7a308b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a270ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f89c00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Deep_Emotion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net\u001b[38;5;241m=\u001b[39m \u001b[43mDeep_Emotion\u001b[49m()\n\u001b[0;32m      2\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Deep_Emotion' is not defined"
     ]
    }
   ],
   "source": [
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17e52ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Rest of the code...\u001b[39;00m\n\u001b[0;32m      5\u001b[0m net \u001b[38;5;241m=\u001b[39m Deep_Emotion()\n\u001b[1;32m----> 6\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Import or define the Deep_Emotion class\n",
    "from deep_emotion import Deep_Emotion\n",
    "\n",
    "# Rest of the code...\n",
    "net = Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d229381",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeep_emotion-1000-128-0.005.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m=\u001b[39m Deep_Emotion()\n\u001b[0;32m      4\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaktrum_by_SOVA_Final.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1559\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;124;03mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[1;32m-> 1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(state_dict)))\n\u001b[0;32m   1561\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1562\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'str'>."
     ]
    }
   ],
   "source": [
    "net.load_state_dict('deep_emotion-1000-128-0.005.pt')\n",
    "\n",
    "net= Deep_Emotion()\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA_Final.pt'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb78d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
