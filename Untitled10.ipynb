{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8449b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deep_Emotion(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=810, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=7, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=640, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from deep_emotion import Deep_Emotion  # Assuming `Deep_Emotion` is defined in a separate module\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Choose the appropriate device\n",
    "\n",
    "net = Deep_Emotion()  # Instantiate the Deep_Emotion model\n",
    "net.load_state_dict(torch.load('Speaktrum_by_SOVA.pt'))  # Load the saved state dictionary\n",
    "net.to(device)  # Move the model to the specified device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe42649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f196946b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2319256047.py, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 82\u001b[1;36m\u001b[0m\n\u001b[1;33m    cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), 1), cv2.LINE_AA)\u001b[0m\n\u001b[1;37m                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define emotions and their corresponding colors\n",
    "emotions = {\n",
    "    0: (\"Angry\", (0, 0, 255)),\n",
    "    2: (\"Fear\", (0, 0, 255)),\n",
    "    3: (\"Happy\", (0, 255, 0)),\n",
    "    4: (\"Sad\", (255, 0, 0))\n",
    "}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if prediction.item() in emotions:\n",
    "                emotion, color = emotions[prediction.item()]\n",
    "                status = emotion\n",
    "            else:\n",
    "                status = \"No emotion detected\"\n",
    "                color = (255, 255, 255)\n",
    "\n",
    "            # Draw background rectangle for the emotion text\n",
    "            bg_rect_height = 60\n",
    "            cv2.rectangle(frame, (x, y - bg_rect_height), (x + w, y), color, -1)\n",
    "\n",
    "            # Draw emotion text\n",
    "            text = f\"Emotion: {status}\"\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, 1)\n",
    "            text_x = x + int((w - text_size[0]) / 2)\n",
    "            text_y = y - bg_rect_height + int((bg_rect_height - text_size[1]) / 2)\n",
    "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), 1), cv2.LINE_AA)\n",
    "\n",
    "    # Display the updated frame\n",
    "    cv2.imshow('Speaktrum', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0a778ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "tensor(3, device='cuda:0')\n",
      "Face not detected\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "Face not detected\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Face not detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    # Check if the webcam is opened correctly\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Define emotions and their corresponding colors\n",
    "emotions = {\n",
    "    0: (\"Angry, take a deep breath\", (0, 0, 255)),\n",
    "    2: (\"Fear, calm down\", (0, 0, 255)),\n",
    "    3: (\"Happy, you are good\", (0, 255, 0)),\n",
    "    4: (\"Sad, relax and meditate\", (255, 0, 0))\n",
    "}\n",
    "\n",
    "# Load the custom logo or watermark image\n",
    "logo = cv2.imread(\"D:\\Anaconda\\Project by me\\Deep-Emotion-master\\logo.png\", cv2.IMREAD_UNCHANGED)\n",
    "logo_height, logo_width = logo.shape[:2]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        facess = faceCascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        if len(facess) == 0:\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in facess:\n",
    "                face_roi = roi_color[ey: ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "            graytemp = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            final_image = cv2.resize(graytemp, (48, 48))\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add third dimension\n",
    "            final_image = np.expand_dims(final_image, axis=0)  # Add fourth dimension\n",
    "            final_image = final_image / 255.0  # Normalization\n",
    "\n",
    "            data = torch.from_numpy(final_image)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            pred = F.softmax(outputs, dim=1)\n",
    "            prediction = torch.argmax(pred)\n",
    "\n",
    "            print(prediction)\n",
    "\n",
    "            if prediction.item() in emotions:\n",
    "                emotion, color = emotions[prediction.item()]\n",
    "                status = emotion\n",
    "            else:\n",
    "                status = \"No emotion detected\"\n",
    "                color = (255, 255, 255)\n",
    "\n",
    "            # Draw background rectangle for the emotion text\n",
    "            bg_rect_height = 60\n",
    "            bg_rect_width = int(w * 1.6)  # Adjust the width of the rectangle\n",
    "            bg_rect_x = x - int((bg_rect_width - w) / 2)  # Adjust the x-coordinate of the rectangle\n",
    "            bg_rect_y = y - bg_rect_height\n",
    "            cv2.rectangle(frame, (bg_rect_x, bg_rect_y), (bg_rect_x + bg_rect_width, y), color, -1)\n",
    "\n",
    "\n",
    "            # Draw emotion text\n",
    "            text = f\"Emotion: {status}\"\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, 1)\n",
    "            text_x = x + int((w - text_size[0]) / 2)\n",
    "            text_y = y - bg_rect_height + int((bg_rect_height - text_size[1]) / 2)\n",
    "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (0, 0, 0),1, cv2.LINE_AA)\n",
    "           \n",
    "        \n",
    "    # Add frame to the whole screen\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    frame_with_frame = cv2.rectangle(frame, (0, 0), (frame_width, frame_height), (255, 255, 255), 40)\n",
    "    \n",
    "    # Add the custom logo or watermark to the frame (top left corner)\n",
    "    logo_resized = cv2.resize(logo, (int(frame_width / 4), int(frame_height / 7)))  # Resize the logo\n",
    "    logo_height, logo_width = logo_resized.shape[:2]\n",
    "    logo_x = 6  # Adjust the x-coordinate of the logo (distance from the left edge)\n",
    "    logo_y = 6  # Adjust the y-coordinate of the logo (distance from the top edge)\n",
    "    alpha_logo = logo_resized[:, :, 3] / 255.0  # Extract alpha channel\n",
    "    alpha_frame = 1.0 - alpha_logo\n",
    "    for c in range(3):\n",
    "        frame[logo_y:logo_y + logo_height, logo_x:logo_x + logo_width, c] = (\n",
    "                alpha_logo * logo_resized[:, :, c] + alpha_frame * frame[logo_y:logo_y + logo_height, logo_x:logo_x + logo_width, c]\n",
    "        )        \n",
    "            \n",
    "            \n",
    "    \n",
    "    # Add frame to the whole screen\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    frame_with_frame = cv2.rectangle(frame, (0, 0), (frame_width, frame_height), (0, 0, 0), 15)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Display the updated frame\n",
    "    cv2.imshow('Speaktrum', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc7b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
